[Generation]

# Standard config
model_name = meta-llama/Llama-3.1-8B-Instruct
frontend = mlir-opt

# File paths
grammar_file = grammars/mlir.lark
example_dir = examples/mlir/general
output_dir = samples/mlir/general

# Generation parameters
max_new_tokens = 1024
num_samples_to_generate = 1000
num_few_shot_examples = 5
prompt_refresh_interval = 10