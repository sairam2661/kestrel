{
  "dialects": {
    "func": 1198,
    "torch": 2352,
    "torch_c": 32,
    "unknown_dialect": 2,
    "arith": 10,
    "test": 3,
    "tosa": 1,
    "scf": 3
  },
  "operations": {
    "func.func": 602,
    "torch.constant.int": 724,
    "torch.operator": 6,
    "func.return": 594,
    "torch.aten.tanh": 7,
    "torch.aten.matmul": 10,
    "torch.constant.none": 93,
    "torch.dtype.calculate": 3,
    "torch.aten.add": 3,
    "torch.dtype.calculate.yield": 3,
    "torch.dtype.calculate.yield.dtypes": 3,
    "torch.aten.log": 6,
    "torch.aten.ge.Tensor": 1,
    "torch.aten.contiguous": 2,
    "torch.aten.size.int": 26,
    "torch.prim.ListConstruct": 269,
    "torch.aten.view": 39,
    "torch.constant.bool": 139,
    "torch.aten.max_pool2d_with_indices": 2,
    "torch.aten.avg_pool2d": 12,
    "torch.aten.index_select": 27,
    "torch.aten.embedding": 2,
    "torch.aten.eq.Tensor": 13,
    "torch.vtensor.literal": 180,
    "torch.constant.float": 84,
    "torch.aten.gt.Scalar": 5,
    "torch.aten.where.Scalar": 3,
    "torch.aten.gt.Tensor": 2,
    "torch.aten.unflatten.int": 1,
    "torch.aten.reciprocal": 2,
    "torch.aten.add.Tensor": 21,
    "torch.aten._shape_as_tensor": 19,
    "torch.aten.item": 31,
    "torch.aten.log2": 2,
    "torch.aten.pow.Tensor_Scalar": 2,
    "torch.aten.mm": 11,
    "torch.aten.mul.Scalar": 3,
    "torch.aten.logical_xor": 1,
    "torch.prim.NumToTensor.Scalar": 13,
    "torch.aten.to.dtype": 9,
    "torch.aten.Int.Scalar": 2,
    "torch.global_slot.module_initializer": 4,
    "torch.initialize.global_slots": 4,
    "torch.global_slot": 4,
    "torch.aten.add.Scalar": 5,
    "torch.aten.unfold": 2,
    "torch.aten.clamp": 4,
    "torch.aten.fft_rfft": 4,
    "torch.aten.permute": 4,
    "torch.aten.clamp.Tensor": 3,
    "torch.constant.str": 29,
    "torch.aten.stft.center": 8,
    "torch.aten.pow.Tensor_Tensor": 2,
    "torch.aten.logit": 2,
    "torch.aten.mul.Tensor": 7,
    "torch.aten.logical_or": 1,
    "torch.aten.slice_scatter": 1,
    "torch.aten.diag_embed": 1,
    "torch.aten.transpose.int": 9,
    "torch.aten.bitwise_and.Tensor": 2,
    "torch.aten.max_pool2d": 8,
    "torch.aten.gather": 1,
    "torch.aten.prod.dim_int": 3,
    "torch.aten.rsqrt": 3,
    "torch.aten.neg": 5,
    "torch.aten.broadcast_to": 10,
    "torch.aten.copy": 1,
    "torch.aten.cat": 13,
    "torch.aten.slice.Tensor": 27,
    "torch.aten.div.Tensor_mode": 11,
    "torch_c.get_next_seed": 1,
    "torch.aten.ones": 2,
    "torch.aten.erf": 2,
    "torch.aten.bitwise_left_shift.Tensor": 2,
    "torch.aten.lt.Tensor": 2,
    "torch.constant.device": 2,
    "torch.aten.empty.memory_format": 1,
    "torch.aten.fill.Scalar": 2,
    "torch.aten.reflection_pad2d": 2,
    "torch.aten.t": 2,
    "torch.onnx.rotary_embedding": 2,
    "torch.aten.expm1": 3,
    "torch.aten.bitwise_and.Scalar": 1,
    "torch.aten.logical_and": 1,
    "torch.aten.sum.dim_IntList": 1,
    "torch.aten.ne.Tensor": 2,
    "torch.aten.flatten.using_ints": 6,
    "torch.aten.fill.Tensor": 1,
    "torch.global_slot.get": 1,
    "torch.aten.gelu": 3,
    "torch.aten.where.self": 9,
    "torch.shape.calculate": 2,
    "torch.shape.calculate.yield": 2,
    "torch.shape.calculate.yield.shapes": 2,
    "torch.tensor_static_info_cast": 2,
    "torch.aten.sub.Scalar": 3,
    "torch.aten.le.Scalar": 4,
    "torch.aten.sub.Tensor": 7,
    "torch.aten.Int.Tensor": 7,
    "torch.aten.abs": 2,
    "torch.aten.uniform": 3,
    "torch.aten.remainder.Scalar": 3,
    "torch.aten.convolution": 10,
    "torch.derefine": 1,
    "torch.aten.batch_norm": 5,
    "torch.aten.any": 1,
    "torch.aten.log10": 2,
    "torch.aten.constant_pad_nd": 2,
    "unknown_dialect.unknown_op": 2,
    "torch.aten.index.Tensor_hacked_twin": 2,
    "torch.aten.avg_pool1d": 4,
    "torch.aten.Float.Tensor": 2,
    "torch.aten.fmod.Tensor": 3,
    "torch.aten.quantize_per_tensor": 4,
    "torch.aten.int_repr": 4,
    "torch.aten._make_per_tensor_quantized_tensor": 14,
    "torch.aten.dequantize.self": 5,
    "torch.aten.where.ScalarOther": 3,
    "torch_c.from_builtin_tensor": 5,
    "torch.aten.min.dim": 1,
    "torch_c.to_builtin_tensor": 4,
    "torch.aten.outer": 1,
    "torch.prim.If": 3,
    "torch.prim.If.yield": 6,
    "torch.aten.lt.float_int": 2,
    "torch.prim.Loop": 6,
    "torch.aten.mul.float": 3,
    "torch.prim.Loop.condition": 6,
    "torch.aten.lt.float": 2,
    "torch.aten.add.float_int": 3,
    "torch.aten.maximum": 2,
    "torch.aten.native_layer_norm": 4,
    "torch.aten.floor": 1,
    "torch.aten.grid_sampler": 4,
    "torch.aten.rsub.Scalar": 7,
    "torch.aten.randn.generator": 2,
    "torch.aten.argmax": 1,
    "torch.aten.mul.int": 1,
    "torch.aten.eq.int": 1,
    "torch.aten.Int.bool": 3,
    "torch.aten.all.dim": 1,
    "torch.aten.sigmoid": 3,
    "torch.aten.unsqueeze": 12,
    "torch.aten.embedding_bag.padding_idx": 1,
    "torch.aten.masked_fill.Scalar": 1,
    "torch.aten.log1p": 2,
    "torch.aten.conv2d": 1,
    "torch.aten.sum": 1,
    "torch.aten.exp": 3,
    "torch.aten.ceil": 1,
    "torch.aten.minimum": 1,
    "torch.aten.leaky_relu": 1,
    "torch.aten.select.int": 8,
    "torch.aten.__interpolate.size_list_scale_list": 5,
    "torch.aten.sin": 1,
    "torch.aten.arange": 2,
    "torch.aten.tan": 2,
    "torch.aten.ge.int": 1,
    "torch.aten._assert_scalar": 2,
    "torch.aten.gt.int": 1,
    "torch.aten.quantize_per_channel": 1,
    "torch.aten._make_per_channel_quantized_tensor": 1,
    "torch.aten.ScalarImplicit": 3,
    "torch.aten.pow.Scalar": 1,
    "torch.aten.lt.Scalar": 6,
    "torch_c.from_i1": 2,
    "torch_c.to_i1": 2,
    "torch_c.from_i64": 4,
    "torch_c.to_i64": 4,
    "torch_c.from_f64": 4,
    "torch_c.to_f64": 4,
    "torch_c.i64_to_generator": 1,
    "torch_c.generator_to_i64": 1,
    "torch.aten.div.Scalar": 2,
    "torch.aten.index.Tensor": 1,
    "torch.aten.diagonal": 1,
    "torch.aten.squeeze.dim": 6,
    "torch.aten.tril": 2,
    "torch.aten.rand": 1,
    "torch.aten.scatter.src": 2,
    "torch.aten.div.Tensor": 5,
    "torch.aten.threshold": 1,
    "torch.aten.any.dim": 1,
    "arith.constant": 6,
    "torch.aten.mean.dim": 1,
    "torch.aten.max_pool1d": 2,
    "torch.prims.split_dim": 2,
    "torch.aten.dequantize.tensor": 9,
    "torch.aten.pad": 1,
    "torch.aten.upsample_nearest2d": 1,
    "torch.aten.empty_like": 1,
    "torch.aten._convolution.deprecated": 1,
    "torch.global_slot.set": 1,
    "torch.aten.sym_constrain_range": 2,
    "torch.aten.one_hot": 1,
    "torch.aten.sinh": 1,
    "torch.aten.round": 1,
    "torch.aten.tensor": 2,
    "torch.prims.convert_element_type": 2,
    "torch.aten.all": 1,
    "arith.extf": 1,
    "arith.truncf": 1,
    "torch.aten._fake_quantize_per_tensor_affine_cachemask_tensor_qparams": 1,
    "torch.bind_symbolic_shape": 5,
    "torch.aten.relu": 2,
    "torch.aten.replication_pad2d": 1,
    "torch.aten.zeros": 2,
    "torch.aten.max_pool3d": 1,
    "torch.aten.flip": 1,
    "torch.aten.reflection_pad3d": 1,
    "func.call": 2,
    "test.use": 1,
    "torch.runtime.assert": 1,
    "torch.aten.eq.Scalar": 3,
    "torch.aten.masked_fill.Tensor": 1,
    "torch.aten.reflection_pad1d": 1,
    "torch.aten.upsample_nearest2d.vec": 1,
    "torch.aten.squeeze": 1,
    "torch.aten.avg_pool3d": 2,
    "torch.aten.floor_divide": 2,
    "tosa.tanh": 1,
    "torch.aten.ne.Scalar": 3,
    "torch.symbolic_int": 2,
    "torch.aten.min": 1,
    "torch.aten.convolution_backward": 1,
    "torch.aten.bitwise_right_shift.Tensor": 2,
    "torch.aten.arange.start_step": 1,
    "torch.aten.max": 1,
    "torch.aten.where.ScalarSelf": 3,
    "test.sink": 1,
    "torch.aten.normal_functional": 1,
    "torch.aten.FloatImplicit": 2,
    "torch.aten.bitwise_not": 1,
    "torch.valsem.aten.bernoulli.float": 1,
    "torch.aten.max.dim": 1,
    "torch.aten.threshold_backward": 1,
    "torch.aten.logical_not": 1,
    "torch.aten.lerp.Tensor": 1,
    "torch.aten.linalg_vector_norm": 1,
    "torch.aten.reshape": 4,
    "scf.while": 1,
    "arith.cmpi": 1,
    "scf.condition": 1,
    "arith.muli": 1,
    "scf.yield": 1,
    "torch.aten.isclose": 1,
    "torch.aten.ge.Scalar": 3,
    "torch.aten.dropout": 1,
    "torch.aten.full": 1,
    "torch.aten.IntImplicit": 2,
    "torch.prims.collapse": 1,
    "torch.aten.sym_constrain_range_for_size": 2,
    "torch.aten.Bool.Tensor": 2,
    "torch.aten.fake_quantize_per_channel_affine_cachemask": 1,
    "torch.aten.bmm": 2,
    "torch.aten.as_strided": 1,
    "torch.aten.remainder.Tensor": 1,
    "torch.aten.max_pool3d_with_indices": 1,
    "test.source": 1,
    "torch.aten.cos": 1,
    "torch.aten.le.Tensor": 1
  },
  "type_patterns": {
    "torchvtensor32388si8torchvtensor32f32torchvtensor32si8torchvtensor32388f32": 1,
    "si8": 71,
    "f32": 2614,
    "torchvtensor32388si8": 1,
    "torchvtensor32f32": 3,
    "torchvtensor32si8": 1,
    "torchvtensorf32torchvtensorf32": 58,
    "torchvtensorf32": 199,
    "torchvtensor256f32torchvtensor256f32torchvtensorf32": 4,
    "torchvtensor256f32": 12,
    "torchinttorchinttorchnumber": 1,
    "torchint": 49,
    "torchvtensorf32torchvtensorf32torchvtensori1": 6,
    "i1": 266,
    "torchvtensorf32torchvtensorf32torchvtensorsi64": 1,
    "si64": 689,
    "torchvtensor136456f32torchvtensor136127f32": 2,
    "torchvtensor136456f32": 2,
    "torchvtensor4f32torchvtensor2si64torchvtensor24f32": 1,
    "torchvtensor4f32": 23,
    "torchvtensor2si64": 3,
    "torchvtensorf32torchvtensorsi64torchvtensorf32": 1,
    "torchvtensorsi64": 23,
    "torchvtensorf32torchvtensor1si64torchvtensor1f32": 1,
    "torchvtensor1si64": 5,
    "i64": 18,
    "torchvtensor4si64torchvtensor4i1": 2,
    "torchvtensor4si64": 24,
    "?xi64?xi64": 1,
    "?xi64": 2,
    "torchvtensor4i1torchvtensor4i1torchvtensor4i1": 6,
    "ui8": 35,
    "torchvtensor164f32torchvtensor1234f32": 1,
    "torchvtensor164f32": 1,
    "torchvtensor8213f32torchvtensor2226f32": 1,
    "torchvtensor8213f32": 1,
    "torchvtensorf32torchvtensorf32torchvtensorf32": 28,
    "torchvtensor5f32torchvtensorsi32": 1,
    "si32": 243,
    "torchvtensor5f32": 8,
    "torchvtensor34si32torchvtensor34f32": 10,
    "torchvtensor34si32": 11,
    "torchvtensor5bf16torchvtensor5bf16": 1,
    "bf16": 53,
    "torchvtensor5bf16": 2,
    "torchvtensori1torchvtensori1torchvtensori1": 2,
    "torchvtensori1": 8,
    "torchvtensor5f32torchvtensorf32": 1,
    "torchvtensor113264si16torchvtensor113264si32": 1,
    "si16": 9,
    "torchvtensor113264si16": 1,
    "torchvtensortorchvtensor": 3,
    "torchvtensor": 27,
    "torchvtensorf32torchvtensor1f32": 11,
    "torchvtensor11128128f32torchvtensor11128128f32": 1,
    "torchvtensor11128128f32": 1,
    "torchvtensor3623f32torchvtensor1923f32": 2,
    "torchvtensor3623f32": 2,
    "torchvtensorf32torchinttorchinttorchvtensorf32": 3,
    "torchvtensor22si32torchvtensor22si32torchvtensor22si64": 1,
    "torchvtensor22si32": 2,
    "torchvtensor342f32torchvtensor324f32": 1,
    "torchvtensor342f32": 3,
    "torchvtensor35f32torchvtensor1f32torchvtensor1f32torchvtensor35f32torchvtensor35f32torchvtensor35f32": 1,
    "torchvtensor35f32": 2,
    "torchvtensor1f32": 5,
    "torchvtensor40f32torchvtensor4f32torchvtensor337f32": 1,
    "torchvtensor40f32": 1,
    "torchvtensor68f32torchvtensor61f32torchvtensor68f32": 1,
    "torchvtensor68f32": 1,
    "torchvtensor61f32": 1,
    "torchvtensor234f32torchvtensor2344f32": 1,
    "torchvtensor234f32": 5,
    "torchvtensor43f32torchvtensor34f32": 2,
    "torchvtensor43f32": 2,
    "torchvtensorsi16torchvtensorsi32torchvtensorsi32": 2,
    "torchvtensorsi16": 2,
    "torchvtensorsi32": 16,
    "torchvtensor117575f32torchvtensor112525f32": 2,
    "torchvtensor117575f32": 2,
    "torchvtensor143f32torchvtensor142si64torchvtensor142f32": 1,
    "torchvtensor143f32": 1,
    "torchvtensor142si64": 1,
    "torchvtensor23f32torchvtensor33f32torchvtensor23f32": 1,
    "torchvtensor23f32": 3,
    "torchvtensor33f32": 3,
    "torchvtensor11128128si64torchvtensor11128128si64": 4,
    "torchvtensor11128128si64": 4,
    "torchvtensor1512si32": 1,
    "torchvtensor1128f32torchvtensor161128f32": 2,
    "torchvtensor1128f32": 2,
    "torchvtensor1155ui8torchvtensor1155i1": 1,
    "torchvtensor1155ui8": 1,
    "torchvtensor144f32torchvtensor24si64": 1,
    "torchvtensor144f32": 4,
    "torchvtensor16456f32torchvtensor15951f32": 1,
    "torchvtensor16456f32": 1,
    "torchvtensorf32torchvtensorsi32torchvtensorf32": 3,
    "torchvtensorsi64torchvtensorsi64torchvtensorsi64": 3,
    "torchvtensor465256f32torchvtensor265256f32": 1,
    "torchvtensor465256f32": 4,
    "torchvtensor34f32": 10,
    "torchvtensor456f32torchvtensor3si32": 1,
    "torchvtensor456f32": 5,
    "torchvtensor34si32torchvtensor31si32torchvtensor34si32": 1,
    "torchvtensor31si32": 1,
    "torchvtensor34si64": 3,
    "torchvtensor12020f32torchvtensor14040f32": 1,
    "torchvtensor12020f32": 1,
    "torchvtensorf32torchvtensor": 1,
    "torchvtensorf32torchvtensor224f32": 1,
    "torchvtensor4i1": 8,
    "torchvtensor1326f32torchvtensortorchvtensortorchvtensortorchvtensor": 1,
    "torchvtensor1326f32": 1,
    "torchvtensorsi32torchvtensorsi32": 1,
    "torchvtensor45i1torchvtensor45i1torchvtensor45i1": 1,
    "torchvtensor45i1": 3,
    "torchvtensor3456f32torchvtensor456f32": 2,
    "torchvtensor3456f32": 2,
    "torchvtensorf32torchvtensor64f32torchvtensori1": 4,
    "torchvtensor64f32": 7,
    "torchvtensorf16torchvtensorf16": 1,
    "f16": 44,
    "torchvtensorf16": 3,
    "torchvtensor1038934f32torchvtensor1034f32": 1,
    "torchvtensor1038934f32": 1,
    "torchvtensor112128128f32torchvtensor1si32torchvtensor112128128f32": 1,
    "torchvtensor112128128f32": 4,
    "torchvtensor1si32": 3,
    "torchvtensor115001536f32torchvtensor115001536f32": 1,
    "torchvtensor115001536f32": 1,
    "torchvtensor64321684f32torchvtensor64843216f32": 1,
    "torchvtensor64321684f32": 1,
    "torchvtensor144f32torchvtensor42si64": 2,
    "torchvtensor1155i1torchvtensor11255f32torchvtensorf32torchvtensor11255f32": 1,
    "torchvtensor1155i1": 1,
    "torchvtensor11255f32": 1,
    "torchvtensor2unktorchvtensor": 1,
    "torchvtensor2unk": 2,
    "torchvtensor112f32torchvtensor142f32": 1,
    "torchvtensor112f32": 1,
    "torchvtensor115656f32torchvtensor112727f32": 2,
    "torchvtensor115656f32": 2,
    "torchvtensorsi8torchint": 1,
    "torchvtensorsi8": 3,
    "torchvtensor1515si64torchvtensor1515si64": 2,
    "torchvtensor1515si64": 2,
    "torchvtensor34f64torchvtensor34f64torchvtensor34f64": 1,
    "f64": 57,
    "torchvtensor34f64": 1,
    "torchvtensor1277f32torchvtensor2433f32torchvtensor1499f32": 1,
    "torchvtensor1277f32": 4,
    "torchvtensor2433f32": 3,
    "torchvtensorf32torchvtensor33f32torchvtensorf32": 1,
    "torchvtensor6f32torchvtensor23f32": 2,
    "torchvtensor6f32": 4,
    "torchvtensor3264f64torchvtensor3264f64": 2,
    "torchvtensor3264f64": 3,
    "torchvtensorf32torchvtensor345f32": 1,
    "torchvtensori1torchvtensor1i1": 2,
    "torchvtensor4256f32torchvtensor256f32torchvtensor4f32": 1,
    "torchvtensor4256f32": 1,
    "torchvtensor34f32torchvtensor34f32": 8,
    "torchvtensor11202044f32torchvtensor11202045f32": 1,
    "torchvtensor11202044f32": 1,
    "torchvtensor4f32torchvtensor1si64torchvtensor14si64torchvtensor4f32": 1,
    "torchvtensor14si64": 1,
    "torchvtensor151210f32torchvtensor151212f32": 2,
    "torchvtensor151210f32": 4,
    "torchvtensor1144f32torchvtensor1122f32": 1,
    "torchvtensor1144f32": 2,
    "?xf32": 7,
    "torchvtensorf64torchfloat": 2,
    "torchvtensorf64": 2,
    "torchvtensor24f32torchvtensor24f32torchvtensor24f32": 2,
    "torchvtensor24f32": 7,
    "torchvtensor244f32torchvtensor244f32": 1,
    "torchvtensor244f32": 1,
    "torchqint8": 34,
    "3x2x3xf323x2x1xf32": 2,
    "3x2x3xf32": 2,
    "torchvtensor3f32torchvtensor4f32torchvtensor34f32": 1,
    "torchvtensor3f32": 8,
    "torchvtensor1388f32torchvtensor1388si8": 1,
    "torchvtensor1388f32": 1,
    "torchbooltorchint": 1,
    "torchbool": 6,
    "torchbooltorchbooltorchint": 1,
    "torchinttorchfloat": 2,
    "torchfloat": 20,
    "torchfloattorchfloat": 2,
    "torchinttorchfloattorchfloat": 1,
    "torchvtensor242si64torchvtensorsi64torchvtensor42si64": 1,
    "torchvtensor242si64": 1,
    "torchvtensor1565696bf16torchlistinttorchvtensor96bf16torchvtensor96bf16torchfloattorchvtensor1565696bf16torchvtensor156561f32torchvtensor156561f32": 1,
    "torchvtensor1565696bf16": 1,
    "torchlistint": 6,
    "torchvtensor96bf16": 2,
    "torchvtensorf32torchinttorchvtensorf32": 5,
    "torchvtensor3f32torchvtensor3f32torchvtensorf32": 1,
    "torchvtensorsi64torchvtensor4si64torchvtensor4si64": 1,
    "torchvtensor20si32torchvtensorsi64": 1,
    "torchvtensor20si32": 1,
    "torchvtensorbf16torchvtensorbf16torchvtensorbf16": 1,
    "torchvtensorbf16": 3,
    "torchinttorchvtensorsi64": 1,
    "torchvtensor112128128f32torchvtensor112128128f32": 1,
    "torchvtensor323i1torchvtensor321i1": 1,
    "torchvtensor323i1": 1,
    "torchvtensor1388si8torchvtensor1388f32": 1,
    "torchvtensor1388si8": 3,
    "torchvtensor456f32torchvtensor406f32torchvtensor456f32": 1,
    "torchvtensor406f32": 1,
    "torchvtensorsi32torchvtensorsi64torchvtensorsi64": 2,
    "torchvtensor1277f32torchvtensor2233f32torchvtensor141515f32": 1,
    "torchvtensor2233f32": 1,
    "torchvtensor1565696f32torchlistinttorchvtensor96f32torchvtensor96f32torchfloattorchvtensor1565696f32torchvtensor156561f32torchvtensor156561f32": 1,
    "torchvtensor1565696f32": 1,
    "torchvtensor96f32": 2,
    "torchvtensorsi32torchvtensorsi32torchvtensorsi32": 3,
    "torchvtensor100000064f32torchvtensor204790si64torchvtensor2048si64torchvtensor204864f32torchvtensor0si64torchvtensor2048si64torchvtensor2048si64": 1,
    "torchvtensor100000064f32": 1,
    "torchvtensor204790si64": 1,
    "torchvtensor2048si64": 1,
    "torchvtensor112128128f32torchvtensor11128128i1torchvtensor112128128f32": 1,
    "torchvtensor11128128i1": 2,
    "torchvtensorsi32torchvtensor1si32torchvtensorsi32": 1,
    "torchvtensor464f32torchvtensor464f32": 1,
    "torchvtensor464f32": 2,
    "torchvtensortorchvtensortorchvtensor": 6,
    "torchvtensor151277f32torchvtensor151211f32": 1,
    "torchvtensor151277f32": 1,
    "torchvtensor1144f32torchvtensor1189f32": 1,
    "torchvtensor256120f32torchvtensor4120256f32torchvtensor4256256f32": 1,
    "torchvtensor256120f32": 1,
    "torchvtensor4120256f32": 1,
    "torchvtensorf32torchvtensor3si64torchvtensorf32": 2,
    "torchvtensor3si64": 4,
    "torchvtensorf32torchvtensorf32torchvtensor222si64": 2,
    "torchvtensor3f32torchvtensor3f32": 4,
    "torchvtensor256f32torchvtensor256f32": 2,
    "torchinttorchint": 4,
    "torchvtensor4377f32torchvtensor4377f32": 1,
    "torchvtensor4377f32": 1,
    "torchvtensor116135240f32torchvtensor116270480f32": 2,
    "torchvtensor116135240f32": 2,
    "torchvtensor4si64torchvtensor4si64torchvtensor4si64": 3,
    "torchnumber": 4,
    "torchvtensor4f32torchvtensor3f32": 1,
    "torchvtensor3322f32torchvtensor12f32": 1,
    "torchvtensor3322f32": 2,
    "?xf32?xi64?xf32?xi64": 1,
    "torchvtensor54i1torchvtensorf32torchvtensor131154f32torchvtensor131154f32": 1,
    "torchvtensor54i1": 1,
    "torchvtensor131154f32": 1,
    "torchvtensor4i1torchvtensor4i1": 1,
    "f32f32": 2,
    "i1i1": 1,
    "i64i64": 2,
    "f64f64": 1,
    "torchvtensor132128bf16torchvtensor132128f16": 1,
    "torchvtensor132128bf16": 1,
    "torchvtensor111si64": 1,
    "torchvtensor144f32torchlistint": 1,
    "torchvtensor268f32torchvtensor6f32torchvtensor2431f32": 1,
    "torchvtensor268f32": 1,
    "torchvtensor3456si32torchvtensor562si32": 1,
    "torchvtensor3456si32": 1,
    "torchvtensor4ui8": 3,
    "torchvtensor24f32torchvtensor4f32": 1,
    "torchvtensorui8torchint": 1,
    "torchvtensorui8": 1,
    "torchvtensorf32torchvtensorf32torchvtensor": 1,
    "torchvtensor11f32torchvtensor1f32": 2,
    "torchvtensor11f32": 2,
    "torchvtensor235f32torchinttorchvtensor235f32": 1,
    "torchvtensor235f32": 1,
    "torchvtensor20020026f64torchvtensor20020026f64": 2,
    "torchvtensor20020026f64": 2,
    "torchvtensor4si32": 1,
    "torchvtensor1086f32torchvtensor243si64torchvtensor243f32torchvtensor1086f32": 1,
    "torchvtensor1086f32": 1,
    "torchvtensor243si64": 1,
    "torchvtensor243f32": 1,
    "torchvtensorf32torchvtensorf32torchvtensor2f32": 2,
    "torchvtensor45si64torchvtensor45si64": 1,
    "torchvtensor45si64": 1,
    "torchvtensor345f32torchvtensor3si64": 1,
    "torchvtensor345f32": 4,
    "torchvtensor3745f32torchvtensor3745f32": 1,
    "torchvtensor3745f32": 1,
    "torchvtensor234f32torchvtensor1234f32": 1,
    "torchvtensor234f32torchvtensor2341f32": 1,
    "torchvtensor234f32torchvtensor2314f32": 1,
    "torchvtensor3456i1torchvtensor456i1": 1,
    "torchvtensor3456i1": 1,
    "torchvtensor12565656f32torchvtensor12562727f32": 1,
    "torchvtensor12565656f32": 2,
    "torchvtensor465256f32torchvtensor433256f32": 1,
    "torchvtensor1833si64torchvtensor122233si64": 1,
    "torchvtensor1833si64": 1,
    "torchvtensor88si8torchvtensor114si8torchvtensor94f32": 1,
    "torchvtensor88si8": 1,
    "torchvtensor114si8": 1,
    "torchvtensor464f32torchvtensor644f32": 1,
    "torchvtensorf32torchvtensor33f32torchvtensorf32torchvtensorf32": 1,
    "?xf32?xf32?xf32?xf32?xf32?xf32": 1,
    "torchvtensorf32torchvtensor84f32": 1,
    "torchvtensorsi64torchint": 2,
    "torchvtensor11112112f32torchvtensor115656f32": 2,
    "torchvtensor11112112f32": 2,
    "torchvtensor24f32torchvtensor24f32": 1,
    "torchvtensorf32torchinttorchvtensori1": 1,
    "torchvtensor3322f32torchvtensorf32": 1,
    "torchvtensor465256f32torchvtensor416256f32": 1,
    "torchvtensor1123f64torchvtensor1189f64": 1,
    "torchvtensor1123f64": 1,
    "torchvtensortorchvtensortorchlistinttorchlistinttorchlistinttorchbooltorchlistinttorchinttorchvtensor": 1,
    "torchvtensor456f32torchvtensor811f32": 1,
    "torchvtensorsi8torchvtensorsi8torchvtensorf32torchvtensorf32": 1,
    "torchqint32": 6,
    "torchvtensor1023f32torchvtensor256f32": 1,
    "torchvtensor1023f32": 1,
    "torchvtensor3si64torchinttorchvtensor3si64": 1,
    "torchvtensor43si32torchvtensor431si32": 2,
    "torchvtensor43si32": 2,
    "torchvtensorf16torchvtensorf32": 1,
    "torchvtensor345f32torchvtensor345f32": 2,
    "torchvtensorsi64torchvtensor4i1": 1,
    "torchvtensor456f32torchvtensor2123f32": 1,
    "torchvtensor64f32torchvtensor64f32": 1,
    "torchvtensor118f16torchvtensor118f16": 1,
    "torchvtensor118f16": 1,
    "torchvtensorsi64torchvtensorsi64torchvtensorsi64torchvtensorsi64": 1,
    "torchvtensor53f32torchvtensor53f32": 1,
    "torchvtensor53f32": 1,
    "torchvtensorf32torchvtensor1f32torchvtensor1si32torchvtensor1si64torchvtensorf32": 1,
    "torchvtensorf32torchfloattorchvtensorf32": 1,
    "torchvtensor816f32torchvtensor168f32torchvtensor88f32": 1,
    "torchvtensor816f32": 1,
    "torchvtensor168f32": 1,
    "torchinttorchinttorchinttorchnumber": 1,
    "torchvtensor6bf16torchvtensor6f32torchfloattorchvtensor6bf16": 1,
    "torchvtensor6bf16": 1,
    "torchvtensor169f32torchvtensor165f32": 2,
    "torchvtensor169f32": 2,
    "torchvtensor1133f32torchvtensor11106f32": 1,
    "torchvtensor1133f32": 3,
    "torchvtensor1f32torchvtensorf32": 1,
    "torchvtensor42f32torchvtensor342f32": 1,
    "torchvtensor42f32": 1,
    "torchvtensorf32torchvtensor5si64torchvtensorf32": 1,
    "torchvtensor5si64": 2,
    "torchvtensor11f32torchvtensor11f32": 1,
    "torchvtensor151210f32torchvtensor151210f32": 2,
    "torchvtensor45734f32torchvtensor451178f32": 1,
    "torchvtensor45734f32": 1,
    "?xf32?xf32": 1,
    "torchvtensor11923535f32torchvtensor11923535f32": 2,
    "torchvtensor11923535f32": 2,
    "torchvtensor323f32torchvtensor321f32": 1,
    "torchvtensor323f32": 3,
    "torchvtensor446f32torchvtensor7f32torchvtensor4440f32": 1,
    "torchvtensor446f32": 1,
    "torchvtensor7f32": 1,
    "torchnone": 1,
    "torchvtensor112128128f32torchvtensor11128128i1torchvtensorf32torchvtensor112128128f32": 1,
    "torchvtensor32f32torchvtensor23f32": 2,
    "torchvtensor124f32torchvtensor128f32": 1,
    "torchvtensor124f32": 1,
    "torchvtensorunk": 2,
    "torchvtensor64f32torchvtensor342f32": 1,
    "torchinttorchinttorchvtensor1si64": 1,
    "2x3xf32torchvtensor23f32": 1,
    "2x3xf32": 1,
    "torchvtensorf32torchvtensor10f32torchvtensor6f32": 1,
    "torchvtensor10f32": 1,
    "torchvtensor1145f32torchvtensor1127f32": 1,
    "torchvtensor1145f32": 1,
    "torchvtensor21212f32torchvtensor222f32": 1,
    "torchvtensor21212f32": 2,
    "torchvtensor112f16torchvtensor112f16": 1,
    "torchvtensor112f16": 1,
    "torchvtensor1376456f32torchvtensor1343154f32": 2,
    "torchvtensor1376456f32": 2,
    "torchvtensorf32torchvtensor1f32torchvtensorf32": 1,
    "torchvtensorf16torchvtensor1f16torchvtensorf16": 1,
    "torchvtensor1f16": 1,
    "?x?xf32?x?xf32": 1,
    "?x?xf32": 1,
    "torchvtensor323f32torchvtensor1f32": 2,
    "torchvtensor232f32torchvtensor2525f32": 1,
    "torchvtensor232f32": 1,
    "torchvtensorf32torchvtensor4f32": 1,
    "torchvtensor5f32torchvtensor3si32": 1,
    "torchvtensor1133f32torchvtensor1155f32torchvtensor1133f32torchvtensorf32torchvtensor1133f32torchvtensor1f32": 1,
    "torchvtensor1155f32": 4,
    "torchvtensorf32torchint": 1,
    "torchvtensor1664f32torchint": 1,
    "torchvtensor1664f32": 2,
    "torchvtensor164112f32torchvtensor16456f32": 1,
    "torchvtensor164112f32": 1,
    "torchany": 2,
    "torchvtensor44si8torchvtensor44si8torchvtensor44f32": 1,
    "torchvtensor44si8": 2,
    "torchvtensorsi64torchvtensor4si64": 1,
    "torchvtensor26f32torchvtensor322f32": 2,
    "torchvtensor26f32": 2,
    "torchvtensor3264f32": 1,
    "torchfloattorchfloattorchint": 1,
    "torchvtensor2unktorchvtensor2unk": 1,
    "torchvtensor261f32torchvtensor8f32torchvtensor2527f32": 1,
    "torchvtensor261f32": 1,
    "torchvtensor8f32": 2,
    "torchvtensor5f32torchvtensor3f32": 1,
    "torchvtensor1024f32torchvtensor1664f32": 1,
    "torchvtensor1024f32": 1,
    "torchvtensor34si64torchvtensor34si64torchvtensor34si64": 1,
    "torchvtensortorchfloattorchGeneratortorchvtensor": 1,
    "torchGenerator": 2,
    "torchvtensor3322335f32torchvtensor3335f32": 2,
    "torchvtensor3322335f32": 2,
    "torchvtensor342f32torchvtensor342f32": 1,
    "torchvtensor131si32torchvtensor131f32torchvtensor131f32": 1,
    "torchvtensor131si32": 1,
    "torchvtensor131f32": 1,
    "torchvtensor1128i1torchvtensor1128si64": 1,
    "torchvtensor1128i1": 1,
    "torchvtensor1641100f32torchvtensor1642200f32": 1,
    "torchvtensor1641100f32": 1,
    "torchvtensor24si32torchvtensor24si32": 1,
    "torchvtensor24si32": 1,
    "torchvtensor24f32torchvtensorf32": 1,
    "torchvtensor1277f32torchvtensor2433f32torchvtensor141616f32": 1,
    "torchvtensor5223f32torchvtensor223f32torchvtensor223f32torchvtensor5223f32": 1,
    "torchvtensor5223f32": 1,
    "torchvtensor223f32": 2,
    "torchvtensor45i1torchvtensor45i1": 1,
    "torchvtensor1256f32torchvtensor256f32torchvtensor1f32": 1,
    "torchvtensor1256f32": 1,
    "torchvtensor1277f32torchvtensor2433f32torchvtensor141515f32": 1,
    "torchvtensorf32torchvtensorf32torchvtensorf32torchvtensorf32": 1,
    "torchvtensor315164f32torchvtensor31511f32": 1,
    "torchvtensor315164f32": 1,
    "torchvtensor5f32torchvtensorsi64": 1,
    "torchvtensortorchfloattorchvtensor": 1,
    "torchnumbertorchvtensor": 1,
    "torchvtensor132220220f32torchvtensor132220220f16": 1,
    "torchvtensor132220220f32": 1,
    "i64i64i64": 1,
    "none": 1,
    "torchbooltorchbool": 1,
    "torchGeneratortorchGenerator": 1,
    "torchvtensor41si64": 1,
    "torchvtensorf32torchvtensori1": 2,
    "torchvtensor2si32": 1,
    "torchvtensorbf16torchvtensorbf16": 1,
    "torchvtensor5f32torchint": 1,
    "torchvtensor456f32torchvtensor2si64torchvtensor452f32": 1,
    "torchvtensor10323f32torchvtensor2356f32": 1,
    "torchvtensor10323f32": 1,
    "torchvtensor55f32torchvtensor55f32torchvtensor55i1": 1,
    "torchvtensor55f32": 3,
    "torchvtensor11si64torchvtensor11si64": 1,
    "torchvtensortorchvtensortorchvtensortorchvtensortorchvtensor": 1,
    "torchvtensor390f32torchvtensor8f32torchvtensor3627f32": 1,
    "torchvtensor390f32": 1,
    "torchvtensor21212f32torchvtensor2212f32": 1,
    "torchvtensor1043f32torchvtensor1043f32": 1,
    "torchvtensor1043f32": 1,
    "torchvtensor35f32torchvtensor35si64": 1,
    "torchvtensor35si64torchvtensor35i1": 1,
    "torchvtensor35si64": 1,
    "torchvtensor1664f32torchvtensor1024f32": 1,
    "torchvtensorf32torchinttorchvtensor11f32": 1,
    "torchvtensor1155f32torchvtensor1155f32torchvtensor1155f32torchvtensor1155f32": 1,
    "torchvtensor1064112112f32torchvtensor10645656f32": 1,
    "torchvtensor1064112112f32": 1,
    "torchvtensorsi64torchlistint": 1,
    "torchvtensor1512si64": 1,
    "torchvtensorf32torchvtensor120464f32": 1,
    "torchvtensor234f32torchvtensor212f32": 1,
    "torchvtensori1torchbool": 2,
    "torchvtensor1388si8torchvtensor3322si8torchvtensor1377f32": 1,
    "torchvtensor3322si8": 2,
    "torchvtensorf32torchvtensorf32torchvtensorsi32torchvtensorf32": 1,
    "torchvtensor4f32torchvtensor4f32torchvtensorf32": 1,
    "torchvtensorf32torchvtensorf32torchfloattorchvtensorf32": 1,
    "torchvtensor55f32torchvtensor33f32": 1,
    "torchvtensor338f32torchvtensorf32torchvtensor3432f32": 1,
    "torchvtensor338f32": 1,
    "torchvtensor345si32torchvtensor345f32torchvtensor345f32": 1,
    "torchvtensor345si32": 1,
    "torchvtensor1064112112112f32torchvtensor1064565656f32": 1,
    "torchvtensor1064112112112f32": 1,
    "*xf32*xf32": 2,
    "*xf32": 2,
    "torchvtensor64f32torchvtensor64si32": 1,
    "torchvtensor61bf16torchvtensor1bf16torchvtensor61bf16": 1,
    "torchvtensor61bf16": 1,
    "torchvtensor1bf16": 1,
    "torchvtensor465256f32torchvtensor41256f32": 1,
    "torchvtensor21283232si8torchvtensor110241024f32": 1,
    "torchvtensor21283232si8": 1,
    "torchvtensor12565656f32torchvtensor12562828f32": 1,
    "torchvtensor1388si8torchvtensor3322si8torchvtensor3f32torchvtensor1377f32": 1,
    "torchvtensor5f32torchvtensor2si32": 1,
    "torchvtensorui32torchvtensorui32torchvtensor2ui32": 1,
    "ui32": 9,
    "torchvtensorui32": 2,
    "torchvtensor35si32torchvtensor35f32": 1,
    "torchvtensor35si32": 1,
    "torchvtensor1034f32torchvtensor1045f32torchvtensor1035f32": 1,
    "torchvtensor1034f32": 1,
    "torchvtensor1045f32": 1,
    "torchvtensor5f32torchvtensor5bf16torchvtensor5f32": 1,
    "torchvtensor410104f32torchvtensor4682f32torchvtensorf32": 1,
    "torchvtensor410104f32": 1,
    "torchvtensor4682f32": 1
  },
  "complexity_metrics": [
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 3,
      "total_ops": 8,
      "total_blocks": 4,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 9,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 12,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 14,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 14,
      "total_blocks": 4,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 1,
      "total_ops": 8,
      "total_blocks": 1,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 2,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 10,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 11,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 8,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 13,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 8,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 9,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 16,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 13,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 24,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 12,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 2,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 11,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 8,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 11,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 3,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 9,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 24,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 3,
      "total_ops": 11,
      "total_blocks": 4,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 10,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 15,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 9,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 13,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 9,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 9,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 25,
      "total_blocks": 3,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 2,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 9,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 8,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 4,
      "total_ops": 55,
      "total_blocks": 17,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 16,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 8,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 11,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 9,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 11,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 11,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 13,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 19,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 9,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 12,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 10,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 8,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 34,
      "total_blocks": 6,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 2,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 8,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 20,
      "total_blocks": 6,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 24,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 9,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 10,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 11,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 19,
      "total_blocks": 3,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 20,
      "total_blocks": 6,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 44,
      "total_blocks": 11,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 12,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 12,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 17,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 12,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 12,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 2,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 15,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 8,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 8,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 9,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 9,
      "total_blocks": 3,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 22,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 8,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 18,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 9,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 8,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 8,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 8,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 3,
      "total_ops": 7,
      "total_blocks": 4,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 8,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 9,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 20,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 19,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 12,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 9,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 2,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 12,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 11,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 9,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 3,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 10,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 2,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 2,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 9,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 8,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 14,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 16,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 10,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 15,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 12,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 9,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 9,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 11,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 12,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 20,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 11,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 2,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 12,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 18,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 16,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 15,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 3,
      "total_ops": 8,
      "total_blocks": 4,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 4,
      "total_ops": 13,
      "total_blocks": 5,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 9,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 13,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 10,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 10,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 10,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 14,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 8,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 8,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 11,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 18,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 11,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 8,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 12,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 13,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 19,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 3,
      "total_ops": 16,
      "total_blocks": 8,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 24,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 8,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 8,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 9,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 14,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 12,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 10,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 9,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 9,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 9,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 10,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 16,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 12,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 8,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 9,
      "total_blocks": 3,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 10,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 15,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 9,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 9,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 10,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 3,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 3,
      "total_ops": 16,
      "total_blocks": 3,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 23,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 12,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 14,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 12,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 4,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 7,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 3,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 6,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    },
    {
      "region_depth": 2,
      "total_ops": 5,
      "total_blocks": 2,
      "ssa_values": 0,
      "functions": 0,
      "modules": 0
    }
  ],
  "structural_templates": [
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[32,3,8,8],si8>, !torch.vtensor<[32],f32>, !torch.vtensor<[32],si8>) -> !torch.vtensor<[32,3,8,8],f32>, sym_name = \"dequantize_p..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.tanh$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n    ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,256],f32>, !torch.vtensor<[256],f32>) -> !torch.vtensor<[?],f32>, sym_name = \"torch.aten.matmul$2dx1d\"}> ({\n  ^bb0(%arg0: !to..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "complex",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.int, !torch.int) -> !torch.number, sym_name = \"refine_dtype$invalid_dtype_for_scalar\"}> ({\n  ^bb0(%arg0: !torch.int, %arg1: !torch.int):..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.log$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n    %..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],i1>, sym_name = \"torch.aten.ge.Tensor$basic\"}> ({\n  ^bb0(%arg0: !..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.contiguous$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>)..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?],f32>) -> !torch.vtensor<[?,?,?],f32>, sym_name = \"view_as_flatten_dynamic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?,?,?]..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?],f32>) -> (!torch.vtensor<[?,?,?],f32>, !torch.vtensor<[?,?,?],si64>), sym_name = \"torch.aten.max_pool2d_with_indices\"}> ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.tanh$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n    ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,3,64,56],f32>) -> !torch.vtensor<[1,3,61,27],f32>, sym_name = \"forward_avg_pool2d_countincludepad_false\"}> ({\n  ^bb0(%arg0: !..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,4],f32>, !torch.vtensor<[2],si64>) -> !torch.vtensor<[2,4],f32>, sym_name = \"torch.aten.index_select$basic\"}> ({\n  ^bb0(%arg4..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> i64, sym_name = \"f0\", sym_visibility = \"private\"}> ({\n  }) : () -> ()\n  \"func.func\"() <{function_type = () -> i64, sym_name = \"f1\", sym_vi..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4],si64>) -> !torch.vtensor<[4],i1>, sym_name = \"aten_eq_tensor_args\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[4],si64>):\n    %0 = \"t..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (memref<?xi64>) -> memref<?xi64>, sym_name = \"i\"}> ({\n  ^bb0(%arg0: memref<?xi64>):\n    \"func.return\"(%arg0) : (memref<?xi64>) -> ()\n  }) : () -..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> (!torch.vtensor<[4],i1>, !torch.vtensor<[4],i1>, !torch.vtensor<[4],i1>), sym_name = \"aten_tensor_tensor_gt\"}> ({\n    %0 = \"torch.vtensor...."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],si64>, sym_name = \"fold_aten_where_true_scalar_int\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<true> : ten..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],i1>, sym_name = \"torch.aten.gt.Tensor$basic\"}> ({\n  ^bb0(%arg0: !..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,6,4],f32>) -> !torch.vtensor<[1,2,3,4],f32>, sym_name = \"torch.aten.unflatten.int$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[1..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[8,?,?,?,2,1,3],f32>) -> !torch.vtensor<[2,2,2,?,?,?,6],f32>, sym_name = \"torch.aten.view$combineConcepts\"}> ({\n  ^bb0(%arg0: !t..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.reciprocal$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>)..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[?],f32>, sym_name = \"elementwise$with_scalar_capture\"}> ({\n  ^bb0(%arg0: !t..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[5,?,?],f32>) -> !torch.vtensor<[],si32>, sym_name = \"shape_as_tensor_dim\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[5,?,?],f32>):\n    ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4],si32>) -> !torch.vtensor<[3,4],f32>, sym_name = \"torch.aten.log2$int\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,4],si32>):\n    ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.pow.Tensor_Scalar$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?],f32>, !torch.vtensor<[?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.mm$no_convert$wrong_rank\"}> ({\n  ^bb0(%a..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[5],bf16>) -> !torch.vtensor<[5],bf16>, sym_name = \"torch.aten.mul.Scalar$mixed_type\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[5],bf16..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],i1>, !torch.vtensor<[?,?],i1>) -> !torch.vtensor<[?,?],i1>, sym_name = \"torch.aten.logical_xor$basic\"}> ({\n  ^bb0(%arg0: !..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[1],si64>, sym_name = \"fold_prim_numtotensor_scalar\"}> ({\n    %0 = \"torch.constant.int\"() <{value = 42 : i64}> : () -> !tor..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[5,?,?],f32>) -> !torch.vtensor<[],f32>, sym_name = \"cast_int_float\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[5,?,?],f32>):\n    %0 = \"..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"torch.global_slot.module_initializer\"() ({\n    %0 = \"torch.constant.int\"() <{value = 1 : i64}> : () -> !torch.int\n    \"torch.initialize.global_slots\"(%0) <{slotSymNames = [@sl..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,1,32,64],si16>) -> !torch.vtensor<[1,1,32,64],si32>, sym_name = \"torch.aten.Scalar$mixed_type\"}> ({\n  ^bb0(%arg0: !torch.vten..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor) -> !torch.vtensor, sym_name = \"basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor):\n    %0 = \"torch.aten.tanh\"(%arg0) : (!torch.vtensor) ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[],f32>) -> !torch.vtensor<[1],f32>, sym_name = \"torch.aten.unfold$rank_zero\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[],f32>):\n    %0..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,1,128,128],f32>) -> !torch.vtensor<[1,1,128,128],f32>, sym_name = \"torch.aten.clamp.float\"}> ({\n  ^bb0(%arg0: !torch.vtensor<..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[36,23],f32>) -> !torch.vtensor<[19,23],complex<f32>>, sym_name = \"torch.aten.fft_rfft$2d_first_dim\"}> ({\n  ^bb0(%arg0: !torch.v..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.int, !torch.int) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.view$dynamictest\"}> ({\n  ^bb0(%arg0: !t..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.view$dynamictest\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>)..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[2,2],si32>, !torch.vtensor<[2,2],si32>) -> !torch.vtensor<[2,2],si64>, sym_name = \"torch.aten.add$int\"}> ({\n  ^bb0(%arg0: !torc..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4,2],f32>) -> !torch.vtensor<[3,2,4],f32>, sym_name = \"torch.aten.permute$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,4,2],f3..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,5],f32>, !torch.vtensor<[1],f32>, !torch.vtensor<[1],f32>) -> (!torch.vtensor<[3,5],f32>, !torch.vtensor<[3,5],f32>, !torch.v..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[40],f32>, !torch.vtensor<[4],f32>) -> !torch.vtensor<[3,37],complex<f32>>, sym_name = \"torch.aten.stft.center_1D\"}> ({\n  ^bb0(%..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.pow.Tensor_Tensor$basic\"}> ({\n  ^bb0..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4],si32>) -> !torch.vtensor<[3,4],f32>, sym_name = \"torch.aten.logit$int\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,4],si32>):\n   ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],f32>, sym_name = \"fold_aten_mul_splat_float\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<7.000000e+00> : te..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],i1>, !torch.vtensor<[?,?],i1>) -> !torch.vtensor<[?,?],i1>, sym_name = \"torch.aten.logical_or$basic\"}> ({\n  ^bb0(%arg0: !t..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[6,8],f32>, !torch.vtensor<[6,1],f32>) -> !torch.vtensor<[6,8],f32>, sym_name = \"torch.aten.slice_scatter$basic\"}> ({\n  ^bb0(%ar..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[2,3,4],f32>) -> !torch.vtensor<[2,3,4,4],f32>, sym_name = \"torch.aten.diag_embed$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[2,3,..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4,3],f32>) -> !torch.vtensor<[3,4],f32>, sym_name = \"torch.aten.transpose$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[4,3],f32>):..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],si16>, !torch.vtensor<[?,?],si32>) -> !torch.vtensor<[?,?],si32>, sym_name = \"torch.aten.bitwise_and.Tensor$mixed_type\"}> ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,1,75,75],f32>) -> !torch.vtensor<[1,1,25,25],f32>, sym_name = \"torch.aten.max_pool2d$full_dim_indivisible_by_stride_with_slic..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,4,3],f32>, !torch.vtensor<[1,4,2],si64>) -> !torch.vtensor<[1,4,2],f32>, sym_name = \"torch.aten.gather\"}> ({\n  ^bb0(%arg0: !t..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[2,3],f32>, !torch.vtensor<[3,3],f32>) -> !torch.vtensor<[2,3],f32>, sym_name = \"torch.aten.mm$basic$static\"}> ({\n  ^bb0(%arg0: ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,1,128,128],si64>) -> !torch.vtensor<[1,1,128,128],si64>, sym_name = \"torch.aten.clamp.min_none\"}> ({\n  ^bb0(%arg0: !torch.vte..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[1,512],si32>, sym_name = \"torch.vtensor.literal_si32$basic\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<-1> : ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?],f32>) -> !torch.vtensor<[?,?,?],f32>, sym_name = \"torch.aten.prod.intdim\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?,?,?],..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.rsqrt$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n   ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,?,128],f32>) -> !torch.vtensor<[16,1,128],f32>, sym_name = \"torch.aten.view$dynamicVal\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[1,..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.neg$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n    %..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,1,5,5],ui8>) -> !torch.vtensor<[1,1,5,5],i1>, sym_name = \"torch.aten.copy\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[1,1,5,5],ui8>):..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,144,?,?],f32>) -> !torch.vtensor<[2,4],si64>, sym_name = \"pytorch_dynamic_pad_export_transpose$prop\"}> ({\n  ^bb0(%arg0: !torc..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,64,56],f32>) -> !torch.vtensor<[1,59,51],f32>, sym_name = \"avgPool2dCHWInput\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[1,64,56],f32..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"torch.global_slot.module_initializer\"() ({\n    \"torch.initialize.global_slots\"() <{slotSymNames = []}> : () -> ()\n  }) : () -> ()\n}) : () -> ()\n\n"
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],si32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.cat$convert\"}> ({\n  ^bb0(%arg0: !to..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],si64>, !torch.vtensor<[?,?],si64>) -> !torch.vtensor<[?,?],si64>, sym_name = \"torch.aten.div.Tensor_mode$int_floor\"}> ({\n ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4,65,256],f32>) -> !torch.vtensor<[2,65,256],f32>, sym_name = \"torch.aten.slice.strided.static$slice_like\"}> ({\n  ^bb0(%arg0: !..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch_c"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> i64, sym_name = \"f\"}> ({\n    %0 = \"torch_c.get_next_seed\"() : () -> i64\n    \"func.return\"(%0) : (i64) -> ()\n  }) : () -> ()\n}) : () -> ()\n..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[3,4],f32>, sym_name = \"torch.aten.ones$basic\"}> ({\n    %0 = \"torch.constant.int\"() <{value = 4 : i64}> : () -> !torch.int\n..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4],si32>) -> !torch.vtensor<[3,4],f32>, sym_name = \"torch.aten.erf$int\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,4],si32>):\n    %..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.rsqrt$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n   ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4,5,6],f32>) -> !torch.vtensor<[3],si32>, sym_name = \"aten_shape_to_tensor\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[4,5,6],f32>):\n  ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?],f32>) -> !torch.vtensor<[?,?,?],f32>, sym_name = \"torch.aten.reciprocal\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?,?],f32>)..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4],si32>, !torch.vtensor<[3,1],si32>) -> !torch.vtensor<[3,4],si32>, sym_name = \"torch.aten.bitwise_left_shift.Tensor\"}> ({\n ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],i1>, sym_name = \"torch.aten.lt.Tensor$basic\"}> ({\n  ^bb0(%arg0: !..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[3,4],si64>, sym_name = \"torch.aten.empty.memory_format$basic\"}> ({\n    %0 = \"torch.constant.int\"() <{value = 0 : i64}> : (..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,20,20],f32>) -> !torch.vtensor<[1,40,40],f32>, sym_name = \"torch.aten.reflection_pad2d$basic\"}> ({\n  ^bb0(%arg0: !torch.vtens..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[3,4,2],f32>, sym_name = \"torch.aten.broadcast_to$fold_splat\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<3.000..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor, sym_name = \"f\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n    %0 = \"torch.aten.t\"(%arg0) : (!..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?],f32>) -> !torch.vtensor<[?,224],f32>, sym_name = \"torch.aten.view$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?,?,?],f..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],i1>, sym_name = \"aten_eq_tensor_dense_fp\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<[4.000000e+00, 5.5000..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,3,2,6],f32>, !torch.vtensor, !torch.vtensor, !torch.vtensor) -> !torch.vtensor, sym_name = \"custom_onnx_rotary_embedding\"}> (..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],si64>, sym_name = \"fold_aten_add_splat_int\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<7> : tensor<4xsi64>..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],f32>, sym_name = \"fold_aten_add_arr1_float\"}> ({\n    %0 = \"torch.constant.float\"() <{value = 2.000000e+00 : f64}> : () ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4],si32>) -> !torch.vtensor<[3,4],f32>, sym_name = \"torch.aten.expm1$int\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,4],si32>):\n   ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],si32>) -> !torch.vtensor<[?,?],si32>, sym_name = \"torch.aten.bitwise_and.Scalar$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4,5],i1>, !torch.vtensor<[4,5],i1>) -> !torch.vtensor<[4,5],i1>, sym_name = \"torch.aten.logical_and$basic\"}> ({\n  ^bb0(%arg0: !..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?],f32>, !torch.vtensor<[?,?,?,?],f32>) -> !torch.vtensor<[?,?,?,?],f32>, sym_name = \"torch.aten.div.Tensor_mode$trunc\"}>..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,?,128],f32>) -> !torch.vtensor<[16,1,128],f32>, sym_name = \"torch.aten.view$dynamicVal\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[1,..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4,5,6],f32>) -> !torch.vtensor<[4,5,6],f32>, sym_name = \"test_reduce_sum_dims$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,4,5..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[64],f32>) -> !torch.vtensor<[?,?],i1>, sym_name = \"torch.aten.ne.tensor\"}> ({\n  ^bb0(%arg0: !torch.v..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f16>) -> !torch.vtensor<[?,?],f16>, sym_name = \"torch.aten.neg.f16\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f16>):\n    %0 ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?],f32>) -> !torch.vtensor<[?,?,?,?],f32>, sym_name = \"torch.aten.max_pool2d\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?,?,?]..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[10,3,8,9,3,4],f32>) -> !torch.vtensor<[10,3,?,4],f32>, sym_name = \"torch.aten.flatten.using_ints$basic\"}> ({\n  ^bb0(%arg0: !tor..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.log$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n    %..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,12,128,128],f32>, !torch.vtensor<[1],si32>) -> !torch.vtensor<[1,12,128,128],f32>, sym_name = \"torch.aten.fill.Tensor\"}> ({\n ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"torch.global_slot\"() <{sym_name = \"slot0\", sym_visibility = \"private\", typeBound = !torch.int}> : () -> ()\n  \"torch.global_slot.module_initializer\"() ({\n    %1 = \"torch.consta..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,1500,1536],f32>) -> !torch.vtensor<[1,1500,1536],f32>, sym_name = \"torch.aten.gelu$none\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[1..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[64,32,16,8,4],f32>) -> !torch.vtensor<[64,8,4,32,16],f32>, sym_name = \"torch.aten.permute\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[6..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,144,?,?],f32>) -> !torch.vtensor<[4,2],si64>, sym_name = \"pytorch_dynamic_pad_export_slice$prop\"}> ({\n  ^bb0(%arg0: !torch.vt..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,1,5,5],i1>, !torch.vtensor<[1,12,5,5],f32>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,12,5,5],f32>, sym_name = \"torch.aten..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "complex",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[2,?],unk>) -> !torch.vtensor, sym_name = \"basic$shape_calculate\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[2,?],unk>):\n    %0 = \"torch..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,1,2],f32>) -> !torch.vtensor<[1,4,2],f32>, sym_name = \"torch.aten.broadcast_to$static_numpy_broadcast\"}> ({\n  ^bb0(%arg0: !to..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.subscalar$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> (!torch.vtensor<[4],i1>, !torch.vtensor<[4],i1>, !torch.vtensor<[4],i1>), sym_name = \"aten_tensor_tensor_le\"}> ({\n    %0 = \"torch.vtensor...."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.addtensor$alpha\"}> ({\n  ^bb0(%arg0: ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,1,56,56],f32>) -> !torch.vtensor<[1,1,27,27],f32>, sym_name = \"torch.aten.avg_pool2d$zero_pad_with_sliced_input\"}> ({\n  ^bb0(..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.sub$basic\"}> ({\n  ^bb0(%arg0: !torch..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[],si8>) -> !torch.int, sym_name = \"torch.aten.Int.Tensor$zero_rank$char_dtype\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[],si8>):\n    ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[15,15],si64>) -> !torch.vtensor<[15,15],si64>, sym_name = \"torch.aten.abs\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[15,15],si64>):\n  ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4],f64>) -> (!torch.vtensor<[3,4],f64>, !torch.vtensor<[3,4],f64>), sym_name = \"torch.aten.uniform$basic\"}> ({\n  ^bb0(%arg0: ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],si64>, sym_name = \"fold_aten_remainder_scalar_int\"}> ({\n    %0 = \"torch.constant.int\"() <{value = 2 : i64}> : () -> !to..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,2,7,7],f32>, !torch.vtensor<[2,4,3,3],f32>) -> !torch.vtensor<[1,4,9,9],f32>, sym_name = \"torch.aten.convolution$transposed_b..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?],f32>, !torch.vtensor<[?,?,3,3],f32>) -> !torch.vtensor<[?,?,?,?],f32>, sym_name = \"torch.aten.convolution\"}> ({\n  ^bb0..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,6,?],f32>) -> !torch.vtensor<[?,2,3,?],f32>, sym_name = \"torch.aten.view$dynamictest2\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,6..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor) -> !torch.vtensor, sym_name = \"adjust_shape_function_arg$optional_tensor\"}> ({\n  ^bb0(%arg0: !torch.vtensor):\n    %0 = \"torch.c..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[32,64],f64>) -> !torch.vtensor<[32,64],f64>, sym_name = \"torch.aten.uniform\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[32,64],f64>):\n ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?],f32>) -> !torch.vtensor<[3,4,5],f32>, sym_name = \"torch.aten.view$castingView\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?,?]..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?],i1>) -> !torch.vtensor<[1],i1>, sym_name = \"test_reduce_any$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?,?,?],i1>):\n ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4,?,256],f32>, !torch.vtensor<[256,?],f32>) -> !torch.vtensor<[4,?,?],f32>, sym_name = \"torch.aten.matmul$basic$dynamic\"}> ({\n ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4],f32>) -> !torch.vtensor<[3,4],f32>, sym_name = \"torch.aten.log10$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,4],f32>):\n   ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[],f32>) -> !torch.vtensor<[],f32>, sym_name = \"torch.aten.permute$rank0\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[],f32>):\n    %0 = \"..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,1,20,20,4,4],f32>) -> !torch.vtensor<[1,1,20,20,4,5],f32>, sym_name = \"torch.aten.constant_pad_nd$basic\"}> ({\n  ^bb0(%arg0: !..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.int, sym_name = \"fold_aten_int_tensor_float\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<3.100000e+00> : tensor<f32>}> ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "unknown_dialect"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> (), sym_name = \"disallowed\"}> ({\n    \"unknown_dialect.unknown_op\"() : () -> ()\n    \"func.return\"() : () -> ()\n  }) : () -> ()\n}) : () -> (..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,4],f32>, !torch.vtensor<[?,1],si64>, !torch.vtensor<[1,4],si64>) -> !torch.vtensor<[?,4],f32>, sym_name = \"torch.aten.index.T..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,512,10],f32>) -> !torch.vtensor<[1,512,12],f32>, sym_name = \"forward_avg_pool1d_countincludepad_false\"}> ({\n  ^bb0(%arg1: !to..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (tensor<?xf32>) -> (), sym_name = \"f\"}> ({\n  ^bb0(%arg0: tensor<?xf32>):\n    \"func.return\"() : () -> ()\n  }) : () -> ()\n}) : () -> ()\n\n"
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[],f64>) -> !torch.float, sym_name = \"torch.aten.Float.Tensor$zero_rank\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[],f64>):\n    %0 = \"t..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[2,4],f32>, !torch.vtensor<[2,4],f32>) -> !torch.vtensor<[2,4],f32>, sym_name = \"torch.aten.fmod.Tensor\"}> ({\n  ^bb0(%arg0: !tor..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[2,4,4],f32>) -> !torch.vtensor<[2,4,4],f32>, sym_name = \"test_quantization_per_tensor\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[2,4,4..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],si64>, sym_name = \"fold_aten_add_splat_int_mismatch\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<7> : tenso..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],f32>, sym_name = \"fold_aten_where_false_sother_fp\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<false> : ten..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch",
        "torch_c"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (tensor<3x2x3xf32>) -> tensor<3x2x1xf32>, sym_name = \"torch.aten.min.dim$basic\"}> ({\n  ^bb0(%arg0: tensor<3x2x3xf32>):\n    %0 = \"torch_c.from_bu..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3],f32>, !torch.vtensor<[4],f32>) -> !torch.vtensor<[3,4],f32>, sym_name = \"torch.aten.outer$basic\"}> ({\n  ^bb0(%arg0: !torch.v..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,3,8,8],f32>) -> !torch.vtensor<[1,3,8,8],si8>, sym_name = \"quantize_per_tensor\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[1,3,8,8],f..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "complex",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.bool) -> !torch.int, sym_name = \"torch.prim.if\"}> ({\n  ^bb0(%arg15: !torch.bool):\n    %30 = \"torch.constant.int\"() <{value = 2 : i64}> :..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[2,4,2],si64>, !torch.vtensor<[],si64>) -> !torch.vtensor<[4,2],si64>, sym_name = \"torch.aten.index.Tensor_hacked_twin\"}> ({\n  ^..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],si64>, sym_name = \"fold_aten_sub_splat_int\"}> ({\n    %0 = \"torch.constant.int\"() <{value = 2 : i64}> : () -> !torch.int..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.maximum$basic\"}> ({\n  ^bb0(%arg0: !t..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,56,56,96],bf16>, !torch.list<int>, !torch.vtensor<[96],bf16>, !torch.vtensor<[96],bf16>, !torch.float) -> (!torch.vtensor<[1,..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.int) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.mulscalar$variable\"}> ({\n  ^bb0(%arg0: !torch.vtens..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.floor$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n   ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,3],f32>, !torch.vtensor<[3,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.mm$basic$dynamic\"}> ({\n  ^bb0(%arg0:..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?],f32>, !torch.vtensor<[?,?,?,?],f32>) -> !torch.vtensor<[?,?,?,?],f32>, sym_name = \"grid_sampler2\"}> ({\n  ^bb0(%arg0: !..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[],si64>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[4],si64>, sym_name = \"fold_aten_where_true_value_nofold\"}> ({\n  ^bb0(%arg..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.rsub.Scalar$float_int\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[32,64],f64>, sym_name = \"torch.aten.randn.generator\"}> ({\n    %0 = \"torch.constant.none\"() : () -> !torch.none\n    %1 = \"t..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[20],si32>) -> !torch.vtensor<[],si64>, sym_name = \"argmax_rank_1\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[20],si32>):\n    %0 = \"torc..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.log2$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n    ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[],bf16>, !torch.vtensor<[],bf16>) -> !torch.vtensor<[],bf16>, sym_name = \"torch.aten.sub.Scalar$mixed_type\"}> ({\n  ^bb0(%arg0: ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,1],f32>, sym_name = \"eq_int_fold\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n    %0 = \"torc..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.int) -> !torch.vtensor<[],si64>, sym_name = \"torch.prim.NumToTensor.Scalar$basic\"}> ({\n  ^bb0(%arg0: !torch.int):\n    %0 = \"torch.prim.N..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,12,128,128],f32>) -> !torch.vtensor<[1,12,128,128],f32>, sym_name = \"torch.aten.fill.Scalar\"}> ({\n  ^bb0(%arg0: !torch.vtenso..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,2,3],i1>) -> !torch.vtensor<[3,2,1],i1>, sym_name = \"torch.aten.all.dim$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,2,3],i1>)..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[],f32>) -> !torch.vtensor<[1],f32>, sym_name = \"torch.aten.flatten.using_ints$rank0\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[],f32>)..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,3,8,8],si8>) -> !torch.vtensor<[1,3,8,8],f32>, sym_name = \"dequantize_per_tensor\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[1,3,8,8]..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4,5,6],f32>, !torch.vtensor<[4,0,6],f32>) -> !torch.vtensor<[4,5,6],f32>, sym_name = \"aten_cat_zero\"}> ({\n  ^bb0(%arg0: !torch...."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.sigmoid$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.cat\"}> ({\n  ^bb0(%arg0: !torch.vtens..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.div.Tensor_mode$float_floor\"}> ({\n  ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],si32>, !torch.vtensor<[?,?],si64>) -> !torch.vtensor<[?,?],si64>, sym_name = \"torch.aten.subtensor$promote\"}> ({\n  ^bb0(%a..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,2,7,7],f32>, !torch.vtensor<[2,2,3,3],f32>) -> !torch.vtensor<[1,4,15,15],f32>, sym_name = \"torch.aten.convolution$transposed..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?],f32>) -> !torch.vtensor<[1,?,?,?,?],f32>, sym_name = \"torch.aten.unsqueeze$dim$0\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,56,56,96],f32>, !torch.list<int>, !torch.vtensor<[96],f32>, !torch.vtensor<[96],f32>, !torch.float) -> (!torch.vtensor<[1,56,..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],si32>, !torch.vtensor<[?,?],si32>) -> !torch.vtensor<[?,?],si32>, sym_name = \"torch.aten.bitwise_and.Tensor$basic\"}> ({\n  ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1000000,64],f32>, !torch.vtensor<[204790],si64>, !torch.vtensor<[2048],si64>) -> (!torch.vtensor<[2048,64],f32>, !torch.vtensor..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,12,128,128],f32>, !torch.vtensor<[1,1,128,128],i1>) -> !torch.vtensor<[1,12,128,128],f32>, sym_name = \"torch.aten.masked_fill..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4],f32>) -> !torch.vtensor<[3,4],f32>, sym_name = \"torch.aten.log1p$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,4],f32>):\n   ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],i1>, sym_name = \"aten_eq_tensor_splat_dense_fp\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<5.000000e+00> :..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?],si32>, !torch.vtensor<[1],si32>) -> !torch.vtensor<[?],si32>, sym_name = \"torch.aten.fmod_int\"}> ({\n  ^bb0(%arg0: !torch.vte..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4,64],f32>) -> !torch.vtensor<[4,64],f32>, sym_name = \"torch.aten.contiguous\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[4,64],f32>):\n ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor, !torch.vtensor) -> !torch.vtensor, sym_name = \"adjust_shape_function_arg$optional\"}> ({\n  ^bb0(%arg0: !torch.vtensor, %arg1: !t..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?],f32>) -> !torch.vtensor<[1],f32>, sym_name = \"test_reduce_sum$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?,?,?],f32>)..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4],si32>) -> !torch.vtensor<[3,4],f32>, sym_name = \"torch.aten.exp$int\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,4],si32>):\n    %..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.ceil$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n    ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],f32>, sym_name = \"fold_aten_where_false_scalar_fp\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<false> : ten..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[],f32>) -> !torch.vtensor<[1],f32>, sym_name = \"torch.aten.view$to_rank1\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[],f32>):\n    %0 = ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,512,7,7],f32>) -> !torch.vtensor<[1,512,1,1],f32>, sym_name = \"torch.aten.avg_pool2d$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.subtensor$basic\"}> ({\n  ^bb0(%arg0: ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.multensor$basic\"}> ({\n  ^bb0(%arg0: ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[256],f32>, !torch.vtensor<[256],f32>) -> !torch.vtensor<[],f32>, sym_name = \"torch.aten.matmul$1dx1d\"}> ({\n  ^bb0(%arg0: !torch..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.int, sym_name = \"fold_aten_int_tensor_bool\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<true> : tensor<i1>}> : () -> !t..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.minimum$basic\"}> ({\n  ^bb0(%arg0: !t..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,1,4,4],f32>) -> !torch.vtensor<[1,1,8,9],f32>, sym_name = \"torch.aten.reflection_pad2d\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[1,..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[256,120],f32>, !torch.vtensor<[4,120,256],f32>) -> !torch.vtensor<[4,256,256],f32>, sym_name = \"torch.aten.matmul$basic$static\"..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.leaky_relu$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>)..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[?,?,?],f32>, sym_name = \"test_resize_nearest_ceil\"}> ({\n  ^bb0(%arg0:..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4],f32>) -> !torch.vtensor<[3,4],f32>, sym_name = \"torch.aten.sin\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,4],f32>):\n    %0 = \"t..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?],f32>, !torch.vtensor<[?,?,?,?],f32>) -> !torch.vtensor<[2,2,2],si64>, sym_name = \"transpose$prop_3d_m1_0\"}> ({\n  ^bb0(..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,3,?,?],f32>) -> !torch.vtensor<[?,3,?,?],f32>, sym_name = \"torch.aten.batch_norm$inference\"}> ({\n  ^bb0(%arg0: !torch.vtensor..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor, sym_name = \"derefine_int_to_number\"}> ({\n    %0 = \"torch.constant.int\"() <{value = 1 : i64}> : () -> !torch.int\n    %1 = \"..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,256],f32>) -> !torch.vtensor<[?,256],f32>, sym_name = \"torch.aten.mm$proj\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,256],f32>):\n ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4],si32>) -> !torch.vtensor<[3,4],f32>, sym_name = \"torch.aten.tan$int\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,4],si32>):\n    %..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.int) -> !torch.int, sym_name = \"torch.aten._assert_scalar\"}> ({\n  ^bb0(%arg0: !torch.int):\n    %0 = \"torch.constant.str\"() <{value = \"Ru..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor, !torch.vtensor) -> !torch.vtensor, sym_name = \"torch.aten.mm$no_convert$missing_dtype\"}> ({\n  ^bb0(%arg0: !torch.vtensor, %arg1..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4,3,7,7],f32>) -> !torch.vtensor<[4,3,7,7],f32>, sym_name = \"test_quantization_per_channel\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,16,135,240],f32>) -> !torch.vtensor<[1,16,270,480],f32>, sym_name = \"torch.aten.__interpolate.size_list_scale_list.nearest\"}>..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4],si64>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[4],si64>, sym_name = \"fold_aten_where_false_value\"}> ({\n  ^bb0(%arg0: !t..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.number, sym_name = \"torch.aten.ScalarImplicit$canonicalize_literal_0d_float\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dens..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[2],si64>, sym_name = \"torch.vtensor.literal$signed\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<1> : tensor<2x..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4],f32>) -> !torch.vtensor<[3,4],f32>, sym_name = \"torch.aten.pow.Scalar\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,4],f32>):\n    ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4],f32>) -> !torch.vtensor<[3],f32>, sym_name = \"torch.aten.slice.tensor$not_fold_slice\"}> ({\n  ^bb0(%arg4: !torch.vtensor<[4],..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4],f32>) -> !torch.vtensor<[3,4],f32>, sym_name = \"torch.aten.expm1$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,4],f32>):\n   ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4],f32>) -> !torch.vtensor<[3,4],f32>, sym_name = \"torch.aten.logit$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,4],f32>):\n   ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,3,2,2],f32>) -> !torch.vtensor<[?,12],f32>, sym_name = \"torch.aten.flatten.using_ints$flatten_back\"}> ({\n  ^bb0(%arg0: !torch..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (memref<?xf32>, memref<?xi64>) -> (memref<?xf32>, memref<?xi64>), sym_name = \"two_return_values\"}> ({\n  ^bb0(%arg0: memref<?xf32>, %arg1: memref..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.gelu\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n    %0 = \"..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[5,4],i1>, !torch.vtensor<[],f32>, !torch.vtensor<[1,3,1,1,5,4],f32>) -> !torch.vtensor<[1,3,1,1,5,4],f32>, sym_name = \"torch.at..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> (!torch.vtensor<[4],i1>, !torch.vtensor<[4],i1>), sym_name = \"aten_tensor_scalar_lt\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = den..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.rsub.Scalar$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch_c"
      ],
      "complexity_class": "complex",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (tensor<f32>) -> tensor<f32>, sym_name = \"eliminate_materializations\"}> ({\n  ^bb0(%arg4: tensor<f32>):\n    %8 = \"torch_c.from_builtin_tensor\"(%a..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.int) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.divscalar$variable\"}> ({\n  ^bb0(%arg0: !torch.vtens..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[256],f32>, !torch.vtensor<[256,?],f32>) -> !torch.vtensor<[?],f32>, sym_name = \"torch.aten.matmul$1dx2d\"}> ({\n  ^bb0(%arg0: !to..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[],f32>, sym_name = \"torch.aten.view$zerod\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n    %0 ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,?,32,128],bf16>) -> !torch.vtensor<[1,?,32,128],f16>, sym_name = \"elementwise_todtype_bf162f16\"}> ({\n  ^bb0(%arg0: !torch.vte..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor, !torch.vtensor) -> !torch.vtensor, sym_name = \"adjust_shape_function_arg$list\"}> ({\n  ^bb0(%arg0: !torch.vtensor, %arg1: !torch..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[1,1,1],si64>, sym_name = \"aten_select_int_fold_3D\"}> ({\n    %0 = \"torch.constant.int\"() <{value = 2 : i64}> : () -> !torch..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.add$basic\"}> ({\n  ^bb0(%arg0: !torch..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,144,?,?],f32>) -> !torch.list<int>, sym_name = \"pytorch_dynamic_pad_export_full\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,144,?,?..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?],f32>) -> !torch.vtensor<[?,1,?],f32>, sym_name = \"torch.aten.slice.last$slice_like\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[2,68],f32>, !torch.vtensor<[6],f32>) -> !torch.vtensor<[2,4,31],complex<f32>>, sym_name = \"torch.aten.stft.center_2D_window_pad..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],i1>, sym_name = \"aten_eq_tensor_splats_int_true\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<5> : tensor<4x..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4,5,6],si32>) -> !torch.vtensor<[5,6,2],si32>, sym_name = \"torch.aten.diagonal$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,4,..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],ui8>, sym_name = \"fold_aten_where_false_sother_int\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<false> : te..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?,2,4],f32>) -> !torch.vtensor<[?,?,?,4],f32>, sym_name = \"view_as_flatten_mid\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?,?,..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],si64>, !torch.vtensor<[?,?],si64>) -> !torch.vtensor<[?,?],si64>, sym_name = \"torch.aten.div.Tensor_mode$int_trunc\"}> ({\n ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[],ui8>) -> !torch.int, sym_name = \"torch.aten.Int.Tensor$zero_rank$byte_dtype\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[],ui8>):\n    ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32>) -> !torch.vtensor, sym_name = \"torch.aten.mm$no_convert$result_missing_dtype\"}> ({\n  ^bb0..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.int, sym_name = \"fold_aten_int_tensor_int\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<3> : tensor<si64>}> : () -> !tor..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],f32>, sym_name = \"fold_aten_sub_splat_float\"}> ({\n    %0 = \"torch.constant.float\"() <{value = 2.000000e+00 : f64}> : ()..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,1,?,1,?],f32>) -> !torch.vtensor<[?,1,?,?],f32>, sym_name = \"torch.aten.squeeze.dim$from_end\"}> ({\n  ^bb0(%arg0: !torch.vtens..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[15,15],si64>) -> !torch.vtensor<[15,15],si64>, sym_name = \"torch.aten.abs\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[15,15],si64>):\n  ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.neg$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n    %..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[2,3,5],f32>, !torch.int) -> !torch.vtensor<[2,3,5],f32>, sym_name = \"torch.aten.tril\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[2,3,5]..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[200,200,26],f64>) -> !torch.vtensor<[200,200,26],f64>, sym_name = \"randNoneDtype\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[200,200,26..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],si32>, sym_name = \"torch.aten.cat$fold_zero_dim_operand\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<[1, 3]..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[10,8,6],f32>, !torch.vtensor<[2,4,3],si64>, !torch.vtensor<[2,4,3],f32>) -> !torch.vtensor<[10,8,6],f32>, sym_name = \"torch.ate..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.number, sym_name = \"torch.aten.ScalarImplicit$canonicalize_numtotensor_0d\"}> ({\n    %0 = \"torch.constant.int\"() <{value = 1 : i64}>..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.div$basic\"}> ({\n  ^bb0(%arg0: !torch..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,2],f32>, sym_name = \"torch.aten.mm$basic_strict\"}> ({\n  ^bb0(%arg0: ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4,5],si64>) -> !torch.vtensor<[4,5],si64>, sym_name = \"torch.aten.threshold$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[4,5],si64..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4,5],f32>) -> !torch.vtensor<[3],si64>, sym_name = \"test_shape\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,4,5],f32>):\n    %0 = \"to..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4],si32>) -> !torch.vtensor<[3,4],f32>, sym_name = \"torch.aten.log10$int\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,4],si32>):\n   ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?],f32>) -> !torch.vtensor<[?,?,?,1,?],f32>, sym_name = \"torch.aten.unsqueeze$from_end\"}> ({\n  ^bb0(%arg0: !torch.vtensor..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,3,?,?],f32>) -> !torch.vtensor<[?,3,?,?],f32>, sym_name = \"torch.aten.batch_norm$no_bias_weight\"}> ({\n  ^bb0(%arg1: !torch.vt..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[],f32>) -> !torch.vtensor<[1],f32>, sym_name = \"torch.aten.unsqueeze$basic\"}> ({\n  ^bb0(%arg4: !torch.vtensor<[],f32>):\n    %8 ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.cat\"}> ({\n  ^bb0(%arg0: !torch.vtens..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4,5,6],i1>) -> !torch.vtensor<[4,5,6],i1>, sym_name = \"test_reduce_any_dim$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,4,5,6]..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "arith",
        "torch",
        "torch_c"
      ],
      "complexity_class": "complex",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.bool, sym_name = \"torch_c.from_i1\"}> ({\n    %22 = \"arith.constant\"() <{value = true}> : () -> i1\n    %23 = \"torch_c.from_i1\"(%22) :..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4,5,6],f32>) -> !torch.vtensor<[4,5,6],f32>, sym_name = \"test_reduce_mean_dim$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,4,5..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?],f32>) -> !torch.vtensor<[?,?,?],f32>, sym_name = \"forward_max_pool1d\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?,?],f32>):\n ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,256,56,56],f32>) -> !torch.vtensor<[1,256,27,27],f32>, sym_name = \"torch.aten.max_pool2d$ceiloff\"}> ({\n  ^bb0(%arg0: !torch.v..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4,65,256],f32>) -> !torch.vtensor<[4,33,256],f32>, sym_name = \"torch.aten.slice.none.static$slice_like\"}> ({\n  ^bb0(%arg0: !tor..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,8,3,3],si64>) -> !torch.vtensor<[1,2,2,2,3,3],si64>, sym_name = \"torch.prims.split_dim$basic\"}> ({\n  ^bb0(%arg0: !torch.vtens..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[64],f32>) -> !torch.vtensor<[?,?],i1>, sym_name = \"torch.aten.eq.tensor\"}> ({\n  ^bb0(%arg0: !torch.v..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[8,8],si8>, !torch.vtensor<[11,4],si8>) -> !torch.vtensor<[9,4],f32>, sym_name = \"mm_pad_commute\"}> ({\n  ^bb0(%arg0: !torch.vten..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4,64],f32>) -> !torch.vtensor<[64,4],f32>, sym_name = \"torch.aten.permute$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[4,64],f32>)..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.erf$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n    %..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],f32>, sym_name = \"fold_aten_add_splat_float\"}> ({\n    %0 = \"torch.constant.float\"() <{value = 2.000000e+00 : f64}> : ()..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?],f32>, !torch.vtensor<[?,?,3,3],f32>, !torch.vtensor<[?],f32>) -> !torch.vtensor<[?,?,?,?],f32>, sym_name = \"torch.aten..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?],f32>) -> !torch.vtensor<[?,?,?,?],f32>, sym_name = \"torch.aten.avg_pool2d$count_include_pad\"}> ({\n  ^bb0(%arg0: !torch..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (memref<?xf32>, memref<?xf32>, memref<?xf32>) -> (memref<?xf32>, memref<?xf32>, memref<?xf32>), sym_name = \"multiple_return_values\"}> ({\n  ^bb0(..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,1,128,128],si64>) -> !torch.vtensor<[1,1,128,128],si64>, sym_name = \"torch.aten.clamp.max_none\"}> ({\n  ^bb0(%arg0: !torch.vte..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[8,4,?],f32>, sym_name = \"torch.aten.broadcast_to$dynamic_implicit\"}> ({\n  ^bb0(%arg0: !torch.vten..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[64],f32>) -> !torch.vtensor<[?,?],i1>, sym_name = \"torch.aten.gt.tensor\"}> ({\n  ^bb0(%arg0: !torch.v..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[],si64>) -> !torch.int, sym_name = \"torch.aten.Int.Tensor$zero_rank\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[],si64>):\n    %0 = \"tor..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,1,112,112],f32>) -> !torch.vtensor<[1,1,56,56],f32>, sym_name = \"torch.aten.avg_pool2d$full_dim_indivisible_by_stride_without..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.mul$basic\"}> ({\n  ^bb0(%arg0: !torch..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[2,4],f32>) -> !torch.vtensor<[2,4],f32>, sym_name = \"torch.aten.remainder.Scalar\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[2,4],f32>)..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.int) -> !torch.vtensor<[?,?],i1>, sym_name = \"torch.aten.gt.scalar$variable\"}> ({\n  ^bb0(%arg0: !torch.vtenso..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,3,2,2],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.flatten.using_ints$flatten_front\"}> ({\n  ^bb0(%arg0: !torch..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],si64>, !torch.vtensor<[?,?],si64>) -> !torch.vtensor<[?,?],si64>, sym_name = \"torch.aten.div.Tensor_mode$int_basic\"}> ({\n ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4,65,256],f32>) -> !torch.vtensor<[4,16,256],f32>, sym_name = \"torch.aten.slice.negative_start\"}> ({\n  ^bb0(%arg0: !torch.vtens..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,1,2,3],f64>) -> !torch.vtensor<[1,1,8,9],f64>, sym_name = \"torch.aten.upsample_nearest2d$basic\"}> ({\n  ^bb0(%arg0: !torch.vte..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[200,200,26],f64>) -> !torch.vtensor<[200,200,26],f64>, sym_name = \"emptyLikeNoneDtype\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[200,2..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?],f32>) -> !torch.vtensor<[?,?,?],f32>, sym_name = \"torch.aten.prod.intdim_negative_dim\"}> ({\n  ^bb0(%arg0: !torch.vtens..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?],f32>) -> !torch.vtensor<[?,?,?,?],f32>, sym_name = \"torch.aten.max_pool2d$padding\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[1],si64>, sym_name = \"aten_select_int_fold_1D\"}> ({\n    %0 = \"torch.constant.int\"() <{value = 1 : i64}> : () -> !torch.int..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor, !torch.vtensor, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int) -> !torch.vten..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],f32>, sym_name = \"fold_aten_add_splat_float_mismatch\"}> ({\n    %0 = \"torch.constant.float\"() <{value = 2.000000e+00 : f..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"torch.global_slot\"() <{sym_name = \"public\", typeBound = !torch.int}> : () -> ()\n  \"torch.global_slot\"() <{sym_name = \"set\", sym_visibility = \"private\", typeBound = !torch.int}..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4,5,6],f32>) -> !torch.vtensor<[8,1,?,1],f32>, sym_name = \"torch.aten$dynamicValOutput\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[4,5,..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?],si8>, !torch.vtensor<[?,?,?,?],si8>, !torch.vtensor<[?],f32>) -> !torch.vtensor<[?,?,?,?],f32>, sym_name = \"q_conv_tes..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],i1>, sym_name = \"torch.aten.eq.Tensor$basic\"}> ({\n  ^bb0(%arg0: !..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.int) -> !torch.int, sym_name = \"torch.aten.sym_constrain_range\"}> ({\n  ^bb0(%arg0: !torch.int):\n    %0 = \"torch.constant.int\"() <{value ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[10,?,2,3],f32>) -> !torch.vtensor<[2,5,?,6],f32>, sym_name = \"torch.aten.view$dynamicInferredSame\"}> ({\n  ^bb0(%arg0: !torch.vt..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.exp$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n    %..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3],si64>, !torch.int) -> !torch.vtensor<[3,?],si64>, sym_name = \"torch.aten.one_hot$fold\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3]..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4,3],si32>) -> !torch.vtensor<[4,3,1],si32>, sym_name = \"torch.aten.unsqueeze$negative_dim\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f16>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.pow.Tensor$mixed_type\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3],f32>) -> !torch.vtensor<[3],f32>, sym_name = \"elementwise_sinh\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3],f32>):\n    %0 = \"torch..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4,5],f32>) -> !torch.vtensor<[3,4,5],f32>, sym_name = \"torch.aten.round\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,4,5],f32>):\n   ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],si32>, !torch.vtensor<[?,?],si64>) -> !torch.vtensor<[?,?],si64>, sym_name = \"torch.aten.addtensor$promote\"}> ({\n  ^bb0(%a..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],f32>, sym_name = \"aten_log$fold_splat_si32\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<3> : tensor<4xsi32>..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],si64>) -> !torch.vtensor<[4],i1>, sym_name = \"eq_tensor_from_tensor_and_literal\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],s..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,6,?],f32>) -> !torch.vtensor<[?,2,3,?],f32>, sym_name = \"torch.aten.view$dynamictest2\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,6..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor) -> !torch.vtensor, sym_name = \"basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor):\n    %0 = \"torch.aten.expm1\"(%arg0) : (!torch.vtensor)..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4,5,6],f32>) -> !torch.vtensor<[2,1,2,3,?],f32>, sym_name = \"torch.aten$dynamicValOutput2\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[4..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4],si32>) -> !torch.vtensor<[3,4],f32>, sym_name = \"torch.aten.tanh$int\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,4],si32>):\n    ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[64],f32>) -> !torch.vtensor<[64],f32>, sym_name = \"torch.prims.convert_element_type$fold\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[64..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,1,8],f16>) -> !torch.vtensor<[1,1,8],f16>, sym_name = \"forward\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[1,1,8],f16>):\n    %0 = \"to..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4],si64>) -> !torch.vtensor<[4],i1>, sym_name = \"torch.aten.lt.Scalar$intfloat\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[4],si64>):\n ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[],f32>, sym_name = \"torch.vtensor.literal$basic\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<0.000000e+00> : t..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],si64>, !torch.vtensor<[?,?],si64>, !torch.vtensor<[?,?],si64>) -> !torch.vtensor<[?,?],si64>, sym_name = \"forward\"}> ({\n  ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?],i1>) -> !torch.vtensor<[1],i1>, sym_name = \"test_reduce_all$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?,?,?],i1>):\n ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "arith"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (f32) -> f32, sym_name = \"extfTruncf\"}> ({\n  ^bb0(%arg0: f32):\n    %0 = \"arith.extf\"(%arg0) : (f32) -> f64\n    %1 = \"arith.truncf\"(%0) : (f64) -..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[5,3],f32>) -> !torch.vtensor<[5,3],f32>, sym_name = \"torch.aten.gelu$tanh\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[5,3],f32>):\n    %..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.number, sym_name = \"torch.aten.ScalarImplicit$canonicalize_literal_0d\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<1> :..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?],f32>, !torch.vtensor<[1],f32>, !torch.vtensor<[1],si32>, !torch.vtensor<[1],si64>) -> !torch.vtensor<[?,?,?,?],f32>, s..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.float) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.addscalar$variable\"}> ({\n  ^bb0(%arg0: !torch.vte..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],si64>, sym_name = \"fold_aten_add_arr0_int\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<[6, 7, 8, 9]> : tens..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[8,16],f32>, !torch.vtensor<[16,8],f32>) -> !torch.vtensor<[8,8],f32>, sym_name = \"torch.aten.matmul.2d\"}> ({\n  ^bb0(%arg0: !tor..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],si32>, !torch.vtensor<[?,?],si32>) -> !torch.vtensor<[?,?],si32>, sym_name = \"torch.aten.bitwise_left_shift.Tensor$basic\"}..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "#map = affine_map<() -> (1)>\n\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?],f32>) -> !torch.vtensor<[?],f32>, sym_name = \"torch.symbolic_int$no_shape_symbols_no_symbols_in..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,3,?,?],f32>) -> !torch.vtensor<[?,3,?,?],f32>, sym_name = \"torch.aten.batch_norm$training\"}> ({\n  ^bb0(%arg0: !torch.vtensor<..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "complex",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.int, !torch.int, !torch.int) -> !torch.number, sym_name = \"refine_dtype$no_simplification\"}> ({\n  ^bb0(%arg0: !torch.int, %arg1: !torch...."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[6],bf16>, !torch.vtensor<[6],f32>, !torch.float) -> !torch.vtensor<[6],bf16>, sym_name = \"torch.aten.add.Tensor$mixed_type_fp\"}..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.relu$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n    ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[16,9],f32>) -> !torch.vtensor<[16,5],complex<f32>>, sym_name = \"torch.aten.fft_rfft$2d_last_dim\"}> ({\n  ^bb0(%arg0: !torch.vten..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,1,3,3],f32>) -> !torch.vtensor<[1,1,10,6],f32>, sym_name = \"torch.aten.replication_pad2d$basic\"}> ({\n  ^bb0(%arg0: !torch.vte..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,2],f32>, sym_name = \"torch.aten.mm$basic\"}> ({\n  ^bb0(%arg0: !torch...."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,512,10],f32>) -> !torch.vtensor<[1,512,12],f32>, sym_name = \"forward_avg_pool1d\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[1,512,10]..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[3,4],f32>, sym_name = \"torch.aten.zeros$basic\"}> ({\n    %0 = \"torch.constant.int\"() <{value = 4 : i64}> : () -> !torch.int..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.subscalar$alpha\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1],f32>) -> !torch.vtensor<[],f32>, sym_name = \"torch.aten.view$to_rank0\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[1],f32>):\n    %0 =..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4,2],f32>) -> !torch.vtensor<[3,4,2],f32>, sym_name = \"torch.aten.broadcast_to$simple_static\"}> ({\n  ^bb0(%arg0: !torch.vtensor..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.divscalar$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?,?],f32>) -> !torch.vtensor<[?,?,?,?,?],f32>, sym_name = \"forward_max_pool3d\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?,?,?..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4,5],f32>) -> !torch.vtensor<[3,4,5],f32>, sym_name = \"torch.aten.flip\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,4,5],f32>):\n    ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?,?],f32>, !torch.vtensor<[5],si64>) -> !torch.vtensor<[?,?,?,?,?],f32>, sym_name = \"test_resize_nearest_3d\"}> ({\n  ^bb0(..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> (!torch.vtensor<[1,1],f32>, !torch.vtensor<[1,1],f32>), sym_name = \"torch.aten.slice.tensor$fold_dim_0\"}> ({\n    %0 = \"torch.vtensor.liter..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,512,10],f32>) -> !torch.vtensor<[1,512,10],f32>, sym_name = \"torch.aten.avg_pool1d$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4,5,7,3,4],f32>) -> !torch.vtensor<[4,5,11,7,8],f32>, sym_name = \"torch.aten.reflection_pad3d$basic\"}> ({\n  ^bb0(%arg0: !torch...."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (memref<?xf32>) -> memref<?xf32>, sym_name = \"f\"}> ({\n  ^bb0(%arg0: memref<?xf32>):\n    \"func.return\"(%arg0) : (memref<?xf32>) -> ()\n  }) : () -..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor, !torch.vtensor) -> !torch.vtensor, sym_name = \"adjust_shape_function_arg$scalar\"}> ({\n  ^bb0(%arg0: !torch.vtensor, %arg1: !tor..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,192,35,35],f32>) -> !torch.vtensor<[1,192,35,35],f32>, sym_name = \"torch.aten.avg_pool2d.count_include_pad_unsupported_value\"..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,2,3],f32>) -> !torch.vtensor<[3,2,1],f32>, sym_name = \"torch.aten.prod.dim_int$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,2,..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?],f32>) -> !torch.vtensor<[?,?,?,?],f32>, sym_name = \"torch.aten.avg_pool2d\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?,?,?]..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4,46],f32>, !torch.vtensor<[7],f32>) -> !torch.vtensor<[4,4,40],complex<f32>>, sym_name = \"torch.aten.stft.center_2D\"}> ({\n  ^b..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch",
        "test"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.none, sym_name = \"none_return\"}> ({\n    %1 = \"torch.constant.none\"() : () -> !torch.none\n    \"func.return\"(%1) : (!torch.none) -> (..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.runtime.assert\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n    %..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> (!torch.vtensor<[4],i1>, !torch.vtensor<[4],i1>, !torch.vtensor<[4],i1>), sym_name = \"aten_tensor_tensor_eq\"}> ({\n    %0 = \"torch.vtensor...."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,12,128,128],f32>, !torch.vtensor<[1,1,128,128],i1>, !torch.vtensor<[],f32>) -> !torch.vtensor<[1,12,128,128],f32>, sym_name =..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],si64>, sym_name = \"fold_aten_div_tensor_mode_int\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<8> : tensor<4..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,2],f32>) -> !torch.vtensor<[2,3],f32>, sym_name = \"torch.aten.view$twotothree\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,2],f32>):..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,2,4],f32>) -> !torch.vtensor<[1,2,8],f32>, sym_name = \"torch.aten.reflection_pad1d$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?],f32>) -> (!torch.vtensor<[?],f32>, !torch.vtensor<[?],f32>), sym_name = \"valid_multiple_ret_values\"}> ({\n  ^bb0(%arg0: !torc..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],si32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.div.Tensor$mixed_type_fp\"}> ({\n  ^b..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[],unk>) -> (), sym_name = \"f\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[],unk>):\n    \"func.return\"() : () -> ()\n  }) : () -> ()\n}) : (..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[6,4],f32>) -> !torch.vtensor<[3,4,2],f32>, sym_name = \"torch.aten.unfold$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[6,4],f32>):\n..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.addscalar$alpha\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.int, !torch.int) -> !torch.vtensor<[1],si64>, sym_name = \"aten_select_int_fold_splat\"}> ({\n  ^bb0(%arg0: !torch.int, %arg1: !torch.int):..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch_c"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (tensor<2x3xf32>) -> !torch.vtensor<[2,3],f32>, sym_name = \"no_seed_needed\"}> ({\n  ^bb0(%arg0: tensor<2x3xf32>):\n    %0 = \"torch_c.from_builtin_..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?],f32>, !torch.vtensor<[10],f32>) -> !torch.vtensor<[6,?],complex<f32>>, sym_name = \"torch.aten.stft.center_1D_unk_sig_len\"}> ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,1,4,5],f32>) -> !torch.vtensor<[1,1,2,7],f32>, sym_name = \"torch.aten.upsample_nearest2d.vec$basic\"}> ({\n  ^bb0(%arg0: !torch..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.addtensor$basic\"}> ({\n  ^bb0(%arg0: ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[2,1,2,1,2],f32>) -> !torch.vtensor<[2,2,2],f32>, sym_name = \"torch.aten.squeeze$static\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[2,1,..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],si64>, sym_name = \"fold_aten_rsub_scalar_int\"}> ({\n    %0 = \"torch.constant.int\"() <{value = 2 : i64}> : () -> !torch.i..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,1,2],f16>) -> !torch.vtensor<[1,1,2],f16>, sym_name = \"forward\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[1,1,2],f16>):\n    %0 = \"to..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,3,7,64,56],f32>) -> !torch.vtensor<[1,3,4,31,54],f32>, sym_name = \"forward_avg_pool3d\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[1,3..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4],f32>) -> !torch.vtensor<[3,4],f32>, sym_name = \"torch.aten.tan$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,4],f32>):\n    %..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[],si64>, sym_name = \"torch.aten.rsub.Scalar$canonicalize_literal_0d\"}> ({\n    %0 = \"torch.constant.int\"() <{value = 2 : i6..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[],f32>) -> !torch.vtensor<[],f32>, sym_name = \"elementwise$unary\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[],f32>):\n    %0 = \"torch.a..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor, !torch.vtensor) -> !torch.vtensor, sym_name = \"op_with_dtype_promotion\"}> ({\n  ^bb0(%arg0: !torch.vtensor, %arg1: !torch.vtenso..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?],f32>, !torch.vtensor<[1],f32>) -> !torch.vtensor<[?],f32>, sym_name = \"elementwise$static_1\"}> ({\n  ^bb0(%arg0: !torch.vtens..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,256],f32>) -> !torch.vtensor<[?,?,256],f32>, sym_name = \"torch.aten.matmul$proj\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?,256..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],f32>, sym_name = \"fold_aten_div_tensor_mode_float\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<8.000000e+00..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,1,56,56],f32>) -> !torch.vtensor<[1,1,27,27],f32>, sym_name = \"torch.aten.max_pool2d$zero_pad_with_sliced_input\"}> ({\n  ^bb0(..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?],f16>, !torch.vtensor<[1],f16>) -> !torch.vtensor<[?],f16>, sym_name = \"torch.aten.fmod_float\"}> ({\n  ^bb0(%arg0: !torch.vten..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "tosa"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (tensor<?x?xf32>) -> tensor<?x?xf32>, sym_name = \"tanh\"}> ({\n  ^bb0(%arg0: tensor<?x?xf32>):\n    %0 = \"tosa.tanh\"(%arg0) : (tensor<?x?xf32>) -> ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.div.Tensor_mode$float_trunc\"}> ({\n  ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?],f32>, !torch.vtensor<[?,?,?,?],f32>) -> !torch.vtensor<[?,?,?,?],f32>, sym_name = \"grid_sampler3\"}> ({\n  ^bb0(%arg0: !..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> (!torch.vtensor<[4],i1>, !torch.vtensor<[4],i1>, !torch.vtensor<[4],i1>), sym_name = \"aten_tensor_tensor_ne\"}> ({\n    %0 = \"torch.vtensor...."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "#map = affine_map<()[s0] -> (s0)>\n#map1 = affine_map<()[s0] -> (s0 + 1)>\n\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?],f32>, !torch.vtensor<[?],f32>) -> !torch.vtensor<[?..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],si16>, !torch.vtensor<[?,?],si32>) -> !torch.vtensor<[?,?],si32>, sym_name = \"torch.aten.div.Tensor$mixed_type_int\"}> ({\n ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,2,3],f32>) -> !torch.vtensor<[1],f32>, sym_name = \"torch.aten.min$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,2,3],f32>):\n   ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],i1>, sym_name = \"aten_eq_tensor_splat_dense_int\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<5> : tensor<4x..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,192,35,35],f32>) -> !torch.vtensor<[1,192,35,35],f32>, sym_name = \"torch.aten.avg_pool2d.divisor_override_unsupported_value\"}..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?],f32>, !torch.int, !torch.int) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.broadcast_to$pure_dynamic_broadcast\"}> ({..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[2,32],f32>) -> !torch.vtensor<[2,5,25],complex<f32>>, sym_name = \"torch.aten.stft.center_2D_no_window\"}> ({\n  ^bb0(%arg0: !torc..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],si64>, sym_name = \"fold_aten_where_true_attr\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<true> : tensor<4x..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],f32>, sym_name = \"fold_aten_remainder_scalar_float\"}> ({\n    %0 = \"torch.constant.float\"() <{value = 2.000000e+00 : f64..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?],f32>) -> !torch.vtensor<[4],f32>, sym_name = \"torch.tensor_static_info_cast$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?],f32..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?],f32>, !torch.vtensor<[?,?,?,?],f32>) -> !torch.vtensor<[?,?,?,?],f32>, sym_name = \"grid_sampler4\"}> ({\n  ^bb0(%arg0: !..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?],f32>) -> !torch.vtensor<[?,?,?],f32>, sym_name = \"f\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?,?],f32>):\n    %0 = \"torch.at..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],si64>) -> !torch.int, sym_name = \"torch.aten.Int.Tensor$non_zero_rank\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],si64>):\n   ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,2],f32>) -> !torch.vtensor<[2,3],f32>, sym_name = \"torch.aten.view$twotothree\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,2],f32>):..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?],f32>, !torch.int, !torch.int) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.broadcast_to$strict_dynamic_broadcast\"}> ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[5,?,?],f32>) -> !torch.vtensor<[3],si32>, sym_name = \"shape_as_tensor\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[5,?,?],f32>):\n    %0 ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,1,3,3],f32>, !torch.vtensor<[1,1,5,5],f32>, !torch.vtensor<[1,1,3,3],f32>, !torch.vtensor<[],f32>) -> (!torch.vtensor<[1,1,3,..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],si32>, !torch.vtensor<[?,?],si32>) -> !torch.vtensor<[?,?],si32>, sym_name = \"torch.aten.bitwise_right_shift.Tensor$basic\"..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.int, sym_name = \"broadcast_prop\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n    %0 = \"torch.constant.i..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[16,9],f32>) -> !torch.vtensor<[16,5],complex<f32>>, sym_name = \"torch.aten.fft_rfft$2d_last_dim\"}> ({\n  ^bb0(%arg0: !torch.vten..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[5],si64>, sym_name = \"torch.aten.arange.start_step\"}> ({\n    %0 = \"torch.constant.none\"() : () -> !torch.none\n    %1 = \"to..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,16,64],f32>) -> !torch.int, sym_name = \"unsqueeze_squeeze_combo\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?,16,64],f32>):\n    %..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,64,112],f32>) -> !torch.vtensor<[1,64,56],f32>, sym_name = \"torch.aten.max_pool1d$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[1..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.any) -> (), sym_name = \"f\"}> ({\n  ^bb0(%arg0: !torch.any):\n    \"func.return\"() : () -> ()\n  }) : () -> ()\n}) : () -> ()\n\n"
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[64],f32>) -> !torch.vtensor<[?,?],i1>, sym_name = \"torch.aten.lt.tensor\"}> ({\n  ^bb0(%arg0: !torch.v..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4,4],si8>, !torch.vtensor<[4,4],si8>) -> !torch.vtensor<[4,4],f32>, sym_name = \"mm\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[4,4],si8..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],si64>) -> !torch.vtensor<[4],si64>, sym_name = \"eq_tensor_and_where_self\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],si64>):\n..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],si64>, sym_name = \"fold_aten_where_false_attr\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<false> : tensor<..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[2,6],f32>) -> !torch.vtensor<[3,2,2],f32>, sym_name = \"torch.aten.view$expandInferredDim\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[2,..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[32,64],f32>, sym_name = \"torch.aten.randn.generator$f32\"}> ({\n    %0 = \"torch.constant.none\"() : () -> !torch.none\n    %1 ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],si64>, sym_name = \"fold_aten_where_true_sother_int\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<true> : ten..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,2,3],f32>) -> !torch.vtensor<[1],f32>, sym_name = \"torch.aten.max$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,2,3],f32>):\n   ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?],f32>, !torch.vtensor<[?,?,?,?],f32>) -> !torch.vtensor<[?,?,?,?],f32>, sym_name = \"torch.aten.div.Tensor_mode$floor\"}>..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],ui8>, sym_name = \"fold_aten_where_false_sself_int\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<false> : ten..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[],si64>, sym_name = \"torch.prim.NumToTensor.Scalar$basic\"}> ({\n    %0 = \"torch.constant.int\"() <{value = 1 : i64}> : () ->..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,1,128,128],si64>) -> !torch.vtensor<[1,1,128,128],si64>, sym_name = \"torch.aten.Scalar$basic\"}> ({\n  ^bb0(%arg0: !torch.vtens..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "test",
        "torch_c"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (tensor<f32>) -> (), sym_name = \"unable_to_convert_lone_tensor_load\"}> ({\n  ^bb0(%arg0: tensor<f32>):\n    %0 = \"torch_c.from_builtin_tensor\"(%ar..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,1,112,112],f32>) -> !torch.vtensor<[1,1,56,56],f32>, sym_name = \"torch.aten.max_pool2d$full_dim_indivisible_by_stride_without..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f64>) -> !torch.float, sym_name = \"torch.aten.Float.Tensor$non_zero_rank\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f64>):\n ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,1,75,75],f32>) -> !torch.vtensor<[1,1,25,25],f32>, sym_name = \"torch.aten.avg_pool2d$full_dim_indivisible_by_stride_with_slic..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[32,64],f64>) -> !torch.vtensor<[32,64],f64>, sym_name = \"torch.aten.normal_functional\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[32,64..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "complex",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.float, !torch.float) -> !torch.int, sym_name = \"refine_dtype$result_type_already_refined\"}> ({\n  ^bb0(%arg0: !torch.float, %arg1: !torch..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "complex",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[2,?],unk>) -> !torch.vtensor<[2,?],unk>, sym_name = \"shape_calc_in_loop\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[2,?],unk>):\n    %0 ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.float, sym_name = \"torch.aten.FloatImplicit$canonicalize_numtotensor_0d\"}> ({\n    %0 = \"torch.constant.float\"() <{value = 1.000000e..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[2,61],f32>, !torch.vtensor<[8],f32>) -> !torch.vtensor<[2,5,27],complex<f32>>, sym_name = \"torch.aten.stft.center_2D_hop_length..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.div.Tensor_mode$float_basic\"}> ({\n  ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],f32>, sym_name = \"fold_aten_where_false_sself_fp\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<false> : tens..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.bitwise_not$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[5,?,?],f32>) -> !torch.vtensor<[3],f32>, sym_name = \"cast_int_float_static\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[5,?,?],f32>):\n  ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],f32>, sym_name = \"aten_log$fold_splat_f32\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<3.000000e+00> : tens..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,1024],f32>) -> !torch.vtensor<[?,?,16,64],f32>, sym_name = \"view_as_unflatten_static\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4,3],f32>) -> !torch.vtensor<[3,4],f32>, sym_name = \"torch.aten.transpose$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[4,3],f32>):..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4],si64>, !torch.vtensor<[3,4],si64>) -> !torch.vtensor<[3,4],si64>, sym_name = \"torch.aten.bitwise_right_shift.Tensor\"}> ({\n..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> (!torch.vtensor<[4],i1>, !torch.vtensor<[4],i1>, !torch.vtensor<[4],i1>), sym_name = \"aten_tensor_tensor_lt\"}> ({\n    %0 = \"torch.vtensor...."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],i1>, sym_name = \"aten_eq_tensor_splats_int_false\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<4> : tensor<4..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor, !torch.float, !torch.Generator) -> !torch.vtensor, sym_name = \"valsem_ops\"}> ({\n  ^bb0(%arg0: !torch.vtensor, %arg1: !torch.flo..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch",
        "torch_c"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (tensor<3x2x3xf32>) -> tensor<3x2x1xf32>, sym_name = \"torch.aten.max.dim$basic\"}> ({\n  ^bb0(%arg0: tensor<3x2x3xf32>):\n    %0 = \"torch_c.from_bu..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,3,2,2,3,3,5],f32>) -> !torch.vtensor<[3,3,?,3,5],f32>, sym_name = \"torch.aten.flatten.using_ints$basic\"}> ({\n  ^bb0(%arg0: !t..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4,2],f32>) -> !torch.vtensor<[3,4,2],f32>, sym_name = \"torch.aten.broadcast_to$fold\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,4,2..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,3,1],si32>, !torch.vtensor<[1,3,1],f32>) -> !torch.vtensor<[1,3,1],f32>, sym_name = \"torch.aten.maximum$mixed_type\"}> ({\n  ^b..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,128],i1>) -> !torch.vtensor<[1,128],si64>, sym_name = \"torch.aten.to.dtype$fromBool\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[1,128..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,64,1,100],f32>) -> !torch.vtensor<[1,64,2,200],f32>, sym_name = \"forward\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[1,64,1,100],f32>..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[2,4],si32>) -> !torch.vtensor<[2,4],si32>, sym_name = \"torch.aten.tril$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[2,4],si32>):\n ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor, !torch.vtensor) -> !torch.vtensor, sym_name = \"turn_tensors_into_rank_and_dtype_args\"}> ({\n  ^bb0(%arg0: !torch.vtensor, %arg1:..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,2,?,4,?],f32>) -> !torch.vtensor<[?],f32>, sym_name = \"torch.aten.view$multiDynamicsInSourceOfCollapse\"}> ({\n  ^bb0(%arg0: !t..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,3,7,64,56],f32>) -> !torch.vtensor<[1,3,4,31,54],f32>, sym_name = \"forward_avg_pool3dd_countincludepad_false\"}> ({\n  ^bb0(%ar..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.exp$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n    %..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,16,135,240],f32>) -> !torch.vtensor<[1,16,270,480],f32>, sym_name = \"torch.aten.__interpolate.size_list_scale_list.bilinear\"}..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.addscalar$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.mulscalar$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],i1>, sym_name = \"aten_eq_tensor_dense_int\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<[4, 5, 6, 6]> : tens..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4],si64>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[4],si64>, sym_name = \"torch.aten.threshold_backward$basic\"}> ({\n  ^bb0(%..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.int, sym_name = \"literal_item\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<[1, 2, 3]> : tensor<3xsi32>}> : () -> !torch..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,2,7,7],f32>, !torch.vtensor<[2,4,3,3],f32>) -> !torch.vtensor<[1,4,16,16],f32>, sym_name = \"torch.aten.convolution$transposed..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[5,2,2,3],f32>, !torch.vtensor<[2,2,3],f32>, !torch.vtensor<[2,2,3],f32>) -> !torch.vtensor<[5,2,2,3],f32>, sym_name = \"torch.at..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"arith_prop\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n    %0 = \"torch..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],ui8>, sym_name = \"fold_aten_where_false_scalar_int\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<false> : te..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4,5],i1>) -> !torch.vtensor<[4,5],i1>, sym_name = \"torch.aten.logical_not\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[4,5],i1>):\n    %0..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[256],f32>, !torch.vtensor<[?,256,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.matmul$1dx3d\"}> ({\n  ^bb0(%arg0:..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"elementwise$binary\"}> ({\n  ^bb0(%arg0: !torch.vte..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,?,256],f32>, !torch.vtensor<[256],f32>) -> !torch.vtensor<[1,?],f32>, sym_name = \"torch.aten.matmul$3dx1d\"}> ({\n  ^bb0(%arg0:..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,2,7,7],f32>, !torch.vtensor<[2,4,3,3],f32>) -> !torch.vtensor<[1,4,15,15],f32>, sym_name = \"torch.aten.convolution$transposed..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?],f32>, !torch.vtensor<[?,?],f32>, !torch.vtensor<[?],f32>) -> !torch.vtensor<[?,?,?],f32>, sym_name = \"elementwise$ternar..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,151,64],f32>) -> !torch.vtensor<[3,151,1],f32>, sym_name = \"test_linalg_vector_norm$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[5,?,?],f32>) -> !torch.vtensor<[],si64>, sym_name = \"cast_int_int\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[5,?,?],f32>):\n    %0 = \"t..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],i1>, sym_name = \"torch.aten.ne.Tensor$basic\"}> ({\n  ^bb0(%arg0: !..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,3,2,2,3,3,5],f32>) -> !torch.vtensor<[3,3,?,3,5],f32>, sym_name = \"torch.aten.flatten.using_ints$basic_negative\"}> ({\n  ^bb0(..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],i1>, sym_name = \"aten_eq_tensor_splats_fp_true\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<5.000000e+00> :..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor, !torch.float) -> !torch.vtensor, sym_name = \"adjust_shape_function_arg$torch.any\"}> ({\n  ^bb0(%arg0: !torch.vtensor, %arg1: !to..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[2,6],f32>) -> !torch.vtensor<[3,2,2],f32>, sym_name = \"torch.aten.view$expandInferredDim\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[2,..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.number) -> !torch.vtensor, sym_name = \"adjust_shape_function_arg$number\"}> ({\n  ^bb0(%arg0: !torch.number):\n    %0 = \"torch.constant.non..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[],f32>, !torch.int) -> !torch.vtensor<[?],f32>, sym_name = \"torch.aten.broadcast_to$empty_input\"}> ({\n  ^bb0(%arg0: !torch.vten..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?],f32>, !torch.vtensor<[3],si64>) -> !torch.vtensor<[?,?,?],f32>, sym_name = \"test_resize_nearest_1d\"}> ({\n  ^bb0(%arg0: !..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?],f32>) -> !torch.vtensor<[?],f32>, sym_name = \"torch.aten.reshape$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?,?,?],f3..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,32,220,220],f32>) -> !torch.vtensor<[1,32,220,220],f16>, sym_name = \"forward\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[1,32,220,220..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?],f32>, !torch.vtensor<[?,?,?,?],f32>) -> !torch.vtensor<[2,2,2],si64>, sym_name = \"transpose$prop_3d_0_1\"}> ({\n  ^bb0(%..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "arith",
        "scf"
      ],
      "complexity_class": "complex",
      "control_flow_type": "complex",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (i64, i64) -> i64, sym_name = \"bwhile\"}> ({\n  ^bb0(%arg4: i64, %arg5: i64):\n    %0 = \"arith.constant\"() <{value = 2 : i64}> : () -> i64\n    %1:2..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,144,?,?],f32>) -> !torch.vtensor<[4,2],si64>, sym_name = \"pytorch_dynamic_pad_export_view$prop\"}> ({\n  ^bb0(%arg0: !torch.vte..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?],f32>) -> !torch.vtensor<[?,?,?],f32>, sym_name = \"torch.aten.slice.none$slice_like\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4,1],si64>, sym_name = \"torch.aten.slice.tensor$fold_dim_0_non_contiguous\"}> ({\n    %0 = \"torch.constant.int\"() <{value = ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],i1>, sym_name = \"torch.aten.le.Scalar$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[2],si32>, sym_name = \"torch.aten.slice.tensor$fold_small\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<[0, 1, 2..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],bf16>) -> !torch.vtensor<[?,?],bf16>, sym_name = \"torch.aten.neg.bf16\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],bf16>):\n   ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],i1>, sym_name = \"aten_eq_tensor_splats_fp_false\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<4.000000e+00> ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[5,?,?],f32>) -> !torch.int, sym_name = \"shape_as_tensor_dim_item\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[5,?,?],f32>):\n    %0 = \"to..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4,5,6],f32>, !torch.vtensor<[2],si64>) -> !torch.vtensor<[4,5,2],f32>, sym_name = \"torch.aten.index_select\"}> ({\n  ^bb0(%arg0: ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[10,3,?,2,3],f32>) -> !torch.vtensor<[2,3,5,?,6],f32>, sym_name = \"torch.aten.view$singleUnknownMatches0\"}> ({\n  ^bb0(%arg0: !to..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[5,5],f32>, !torch.vtensor<[5,5],f32>) -> !torch.vtensor<[5,5],i1>, sym_name = \"torch.aten.isclose$basic\"}> ({\n  ^bb0(%arg0: !to..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,3,64,56],f32>) -> !torch.vtensor<[1,3,61,27],f32>, sym_name = \"forward_avg_pool2d\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[1,3,64,..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4,3],si32>) -> !torch.vtensor<[4,3,1],si32>, sym_name = \"torch.aten.unsqueeze$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[4,3],si..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> (!torch.vtensor<[1,1],si64>, !torch.vtensor<[1,1],si64>), sym_name = \"torch.aten.slice.tensor$fold_dim_1\"}> ({\n    %0 = \"torch.vtensor.lit..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor, !torch.vtensor, !torch.vtensor, !torch.vtensor) -> !torch.vtensor, sym_name = \"custom_onnx_rotary_embedding\"}> ({\n  ^bb0(%arg0:..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[],si64>, sym_name = \"torch.prim.NumToTensor.Scalar\"}> ({\n    %0 = \"torch.constant.int\"() <{value = 1 : i64}> : () -> !torc..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> (!torch.vtensor<[4],i1>, !torch.vtensor<[4],i1>, !torch.vtensor<[4],i1>), sym_name = \"aten_tensor_tensor_ge\"}> ({\n    %0 = \"torch.vtensor...."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,90],f32>, !torch.vtensor<[8],f32>) -> !torch.vtensor<[3,6,27],complex<f32>>, sym_name = \"torch.aten.stft.center_2D_hop_length..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[2,1,2,1,2],f32>) -> !torch.vtensor<[2,2,1,2],f32>, sym_name = \"torch.aten.squeeze.dim$0$static\"}> ({\n  ^bb0(%arg0: !torch.vtens..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[10,4,3],f32>) -> !torch.vtensor<[10,4,3],f32>, sym_name = \"torch.aten.native_batch_norm$basic\"}> ({\n  ^bb0(%arg0: !torch.vtenso..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,5],f32>) -> !torch.vtensor<[3,5],si64>, sym_name = \"torch.aten.to.dtype$floatToInt\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,5],f..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],si64>, sym_name = \"fold_aten_add_arr1_int\"}> ({\n    %0 = \"torch.constant.int\"() <{value = 2 : i64}> : () -> !torch.int\n..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,5],si64>) -> !torch.vtensor<[3,5],i1>, sym_name = \"torch.aten.to.dtype$toBool\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,5],si64>)..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],si32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.cat$convert\"}> ({\n  ^bb0(%arg0: !to..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,16,64],f32>) -> !torch.vtensor<[?,?,1024],f32>, sym_name = \"view_as_flatten_static\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?,..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.dropout$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?],f32>, !torch.int) -> !torch.vtensor<[?,1,?,1],f32>, sym_name = \"torch.aten$dynamicValOutput\"}> ({\n  ^bb0(%arg0: !torch.v..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,1,5,5],f32>, !torch.vtensor<[1,1,5,5],f32>, !torch.vtensor<[1,1,5,5],f32>) -> !torch.vtensor<[1,1,5,5],f32>, sym_name = \"scal..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.neg\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n    %0 = \"t..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[10,64,112,112],f32>) -> !torch.vtensor<[10,64,56,56],f32>, sym_name = \"torch.aten.max_pool2d_with_indices$canonicalize\"}> ({\n  ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?],f32>) -> !torch.vtensor<[?,?,?,?],f32>, sym_name = \"forward_max_pool2d\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?,?,?],f3..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],si64>) -> !torch.list<int>, sym_name = \"squeeze_dim_full_fold\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],si64>):\n    %0 = \"t..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,1,?,1,?],f32>) -> !torch.vtensor<[?,?,1,?],f32>, sym_name = \"torch.aten.squeeze.dim$1\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,1..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4],si32>) -> !torch.vtensor<[3,4],f32>, sym_name = \"torch.aten.log$int\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,4],si32>):\n    %..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[1,512],si64>, sym_name = \"torch.vtensor.literal_si64$basic\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<-1> : ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?,?],f32>) -> !torch.vtensor<[?,120,4,64],f32>, sym_name = \"torch.aten.reshape$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.int, sym_name = \"torch.aten.IntImplicit$canonicalize_numtotensor_0d\"}> ({\n    %2 = \"torch.constant.int\"() <{value = 1 : i64}> : () ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,512,10],f32>) -> !torch.vtensor<[1,512,10],f32>, sym_name = \"torch.aten.avg_pool1d.count_include_pad_unsupported_value\"}> ({\n..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,1,128,128],si64>) -> !torch.vtensor<[1,1,128,128],si64>, sym_name = \"torch.aten.clamp\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[1,1..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[2,3,4],f32>) -> !torch.vtensor<[2,12],f32>, sym_name = \"torch.prims.collapse$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[2,3,4],f..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],f32>, sym_name = \"fold_aten_add_arr0_float\"}> ({\n    %0 = \"torch.constant.float\"() <{value = 2.000000e+00 : f64}> : () ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.divtensor$basic\"}> ({\n  ^bb0(%arg0: ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4],si64>, !torch.vtensor<[4],si64>) -> !torch.vtensor<[4],si64>, sym_name = \"fold_aten_where_true_value\"}> ({\n  ^bb0(%arg0: !to..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.int) -> !torch.int, sym_name = \"torch.aten.sym_constrain_range_for_size\"}> ({\n  ^bb0(%arg0: !torch.int):\n    %0 = \"torch.constant.int\"()..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],i1>) -> !torch.bool, sym_name = \"torch.aten.Bool.Tensor$non_zero_rank\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],i1>):\n    %..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,3,8,8],si8>, !torch.vtensor<[3,3,2,2],si8>) -> !torch.vtensor<[1,3,7,7],f32>, sym_name = \"convolution_nobias\"}> ({\n  ^bb0(%ar..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?],f32>, !torch.vtensor<[?],f32>, !torch.vtensor<[?],si32>) -> !torch.vtensor<[?,?,?,?],f32>, sym_name = \"torch.aten.fake..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,4],f32>, !torch.vtensor<[?,4,?],f32>) -> !torch.vtensor<[?,?,?],f32>, sym_name = \"torch.aten.bmm$basic$dynamic\"}> ({\n  ^bb0..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.rsubscalar$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>)..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32>, !torch.float) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.addtensor$variable\"}> ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[5,5],f32>) -> !torch.vtensor<[3,3],f32>, sym_name = \"torch.aten.as_strided$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[5,5],f32>)..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[],i1>) -> !torch.bool, sym_name = \"torch.aten.Bool.Tensor$zero_rank\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[],i1>):\n    %0 = \"torch..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.subtensor$alpha\"}> ({\n  ^bb0(%arg0: ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,38],f32>, !torch.vtensor<[?],f32>) -> !torch.vtensor<[3,4,32],complex<f32>>, sym_name = \"torch.aten.stft.center_2D_win_unk_si..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.rsqrt$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n   ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?],f32>) -> !torch.vtensor<[?,?,?],f32>, sym_name = \"torch.aten.slice.strided$slice_like\"}> ({\n  ^bb0(%arg0: !torch.vtensor..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.relu\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n    %0 = \"..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4,5],si32>, !torch.vtensor<[3,4,5],f32>) -> !torch.vtensor<[3,4,5],f32>, sym_name = \"torch.aten.pow.Tensor_Tensor$intfloat\"}>..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4],si32>) -> !torch.vtensor<[3,4],f32>, sym_name = \"torch.aten.log1p$int\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,4],si32>):\n   ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "unknown_dialect"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> (), sym_name = \"disallowed\"}> ({\n    \"unknown_dialect.unknown_op\"() : () -> ()\n    \"func.return\"() : () -> ()\n  }) : () -> ()\n}) : () -> (..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[2,4],f32>, !torch.vtensor<[2,4],f32>) -> !torch.vtensor<[2,4],f32>, sym_name = \"torch.aten.remainder.Tensor\"}> ({\n  ^bb0(%arg0:..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],si64>, sym_name = \"fold_aten_where_true_sself_int\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<true> : tens..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[10,64,112,112,112],f32>) -> !torch.vtensor<[10,64,56,56,56],f32>, sym_name = \"torch.aten.max_pool3d_with_indices$canonicalize\"}..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (tensor<*xf32>) -> tensor<*xf32>, sym_name = \"called\"}> ({\n  ^bb0(%arg1: tensor<*xf32>):\n    \"func.return\"(%arg1) : (tensor<*xf32>) -> ()\n  }) :..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[64],f32>) -> !torch.vtensor<[64],si32>, sym_name = \"torch.prims.convert_element_type$no_fold\"}> ({\n  ^bb0(%arg0: !torch.vtensor..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "complex",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[2,3],f32>, sym_name = \"torch.prim.Loop$for_with_tensor_arg\"}> ({\n    %0 = \"torch.constant.bool\"() <{value = true}> : () ->..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?,?,?],f32>) -> !torch.vtensor<[?,1,?,?,?],f32>, sym_name = \"torch.aten.unsqueeze$dim$1\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[6,1],bf16>, !torch.vtensor<[1],bf16>) -> !torch.vtensor<[6,1],bf16>, sym_name = \"elementwise_add_non_broadcast_unit_dims\"}> ({\n..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "test",
        "torch_c"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> tensor<f32>, sym_name = \"unable_to_convert_lone_buffer_cast\"}> ({\n    %0 = \"test.source\"() : () -> !torch.vtensor<[],f32>\n    %1 = \"torch_..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4,65,256],f32>) -> !torch.vtensor<[4,1,256],f32>, sym_name = \"torch.aten.slice.last.static$slice_like\"}> ({\n  ^bb0(%arg0: !torc..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "complex",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[2,128,32,32],si8>) -> !torch.vtensor<[1,1024,1024],f32>, sym_name = \"matmul_commuting\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[2,128..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],f32>, sym_name = \"fold_aten_rsub_scalar_float\"}> ({\n    %0 = \"torch.constant.float\"() <{value = 2.000000e+00 : f64}> : ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,256,56,56],f32>) -> !torch.vtensor<[1,256,28,28],f32>, sym_name = \"torch.aten.max_pool2d$ceilon\"}> ({\n  ^bb0(%arg0: !torch.vt..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[1,3,8,8],si8>, !torch.vtensor<[3,3,2,2],si8>, !torch.vtensor<[3],f32>) -> !torch.vtensor<[1,3,7,7],f32>, sym_name = \"convolutio..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[5,?,?,?],f32>) -> !torch.vtensor<[2],si32>, sym_name = \"shape_as_tensor_slice\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[5,?,?,?],f32>..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],ui32>, !torch.vtensor<[?,?],ui32>) -> !torch.vtensor<[?,2],ui32>, sym_name = \"torch.aten.mm$basic_unsigned\"}> ({\n  ^bb0(%a..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,5],si32>) -> !torch.vtensor<[3,5],f32>, sym_name = \"torch.aten.sigmoid$int\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,5],si32>):\n ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],i1>, sym_name = \"torch.aten.gt.scalar\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n    %0..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[10,3,4],f32>, !torch.vtensor<[10,4,5],f32>) -> !torch.vtensor<[10,3,5],f32>, sym_name = \"torch.aten.bmm$basic$static\"}> ({\n  ^b..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.float, sym_name = \"torch.aten.FloatImplicit$canonicalize_literal_0d\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<1.0000..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[5],f32>, !torch.vtensor<[5],bf16>) -> !torch.vtensor<[5],f32>, sym_name = \"torch.aten.add.Tensor$mixed_type_int\"}> ({\n  ^bb0(%a..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],f32>, sym_name = \"fold_aten_div_tensor_mode_none\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<8> : tensor<4..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],si64>, sym_name = \"fold_aten_mul_splat_int\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<7> : tensor<4xsi64>..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],f32>, sym_name = \"torch.aten.sigmoid$basic\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[?,?],f32>):\n ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[4],f32>, sym_name = \"aten_log$fold_splat_i1\"}> ({\n    %0 = \"torch.vtensor.literal\"() <{value = dense<true> : tensor<4xi1>}..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[3,4],f32>) -> !torch.vtensor<[3,4],f32>, sym_name = \"torch.aten.cos\"}> ({\n  ^bb0(%arg0: !torch.vtensor<[3,4],f32>):\n    %0 = \"t..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = () -> !torch.vtensor<[],si64>, sym_name = \"torch.aten.rsub.Scalar$canonicalize_numtotensor_0d\"}> ({\n    %0 = \"torch.constant.int\"() <{value = 1 ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[?,?],f32>, !torch.vtensor<[?,?],f32>) -> !torch.vtensor<[?,?],i1>, sym_name = \"torch.aten.le.Tensor$basic\"}> ({\n  ^bb0(%arg0: !..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[4,10,10,4],f32>, !torch.vtensor<[4,6,8,2],f32>) -> !torch.vtensor<[?,?,?,?],f32>, sym_name = \"grid_sampler\"}> ({\n  ^bb0(%arg0: ..."
    },
    {
      "has_module": false,
      "num_functions": 0,
      "dialects_used": [
        "func",
        "torch"
      ],
      "complexity_class": "medium",
      "control_flow_type": "simple",
      "code_snippet": "\"builtin.module\"() ({\n  \"func.func\"() <{function_type = (!torch.vtensor<[36,23],f32>) -> !torch.vtensor<[19,23],complex<f32>>, sym_name = \"torch.aten.fft_rfft$2d_first_dim\"}> ({\n  ^bb0(%arg0: !torch.v..."
    }
  ],
  "total_files": 560,
  "parsed_successfully": 560,
  "parse_errors": [],
  "statistics": {
    "top_dialects": [
      [
        "torch",
        2352
      ],
      [
        "func",
        1198
      ],
      [
        "torch_c",
        32
      ],
      [
        "arith",
        10
      ],
      [
        "test",
        3
      ],
      [
        "scf",
        3
      ],
      [
        "unknown_dialect",
        2
      ],
      [
        "tosa",
        1
      ]
    ],
    "top_operations": [
      [
        "torch.constant.int",
        724
      ],
      [
        "func.func",
        602
      ],
      [
        "func.return",
        594
      ],
      [
        "torch.prim.ListConstruct",
        269
      ],
      [
        "torch.vtensor.literal",
        180
      ],
      [
        "torch.constant.bool",
        139
      ],
      [
        "torch.constant.none",
        93
      ],
      [
        "torch.constant.float",
        84
      ],
      [
        "torch.aten.view",
        39
      ],
      [
        "torch.aten.item",
        31
      ],
      [
        "torch.constant.str",
        29
      ],
      [
        "torch.aten.index_select",
        27
      ],
      [
        "torch.aten.slice.Tensor",
        27
      ],
      [
        "torch.aten.size.int",
        26
      ],
      [
        "torch.aten.add.Tensor",
        21
      ],
      [
        "torch.aten._shape_as_tensor",
        19
      ],
      [
        "torch.aten._make_per_tensor_quantized_tensor",
        14
      ],
      [
        "torch.aten.eq.Tensor",
        13
      ],
      [
        "torch.prim.NumToTensor.Scalar",
        13
      ],
      [
        "torch.aten.cat",
        13
      ]
    ],
    "top_types": [
      [
        "f32",
        2614
      ],
      [
        "si64",
        689
      ],
      [
        "i1",
        266
      ],
      [
        "si32",
        243
      ],
      [
        "torchvtensorf32",
        199
      ],
      [
        "si8",
        71
      ],
      [
        "torchvtensorf32torchvtensorf32",
        58
      ],
      [
        "f64",
        57
      ],
      [
        "bf16",
        53
      ],
      [
        "torchint",
        49
      ],
      [
        "f16",
        44
      ],
      [
        "ui8",
        35
      ],
      [
        "torchqint8",
        34
      ],
      [
        "torchvtensorf32torchvtensorf32torchvtensorf32",
        28
      ],
      [
        "torchvtensor",
        27
      ]
    ],
    "avg_ops_per_file": 6.430357142857143,
    "avg_region_depth": 2.0160714285714287,
    "complexity_distribution": {
      "medium": 525,
      "complex": 35
    }
  }
}